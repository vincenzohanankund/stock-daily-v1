# -*- coding: utf-8 -*-
"""
===================================
Web æœåŠ¡å±‚ - ä¸šåŠ¡é€»è¾‘
===================================

èŒè´£ï¼š
1. é…ç½®ç®¡ç†æœåŠ¡ (ConfigService)
2. åˆ†æä»»åŠ¡æœåŠ¡ (AnalysisService)
"""

from __future__ import annotations

import os
import re
import logging
import threading
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from typing import Optional, Dict, Any, List, Union

from src.enums import ReportType
from bot.models import BotMessage

logger = logging.getLogger(__name__)

# ============================================================
# é…ç½®ç®¡ç†æœåŠ¡
# ============================================================

_ENV_PATH = os.getenv("ENV_FILE", ".env")

_STOCK_LIST_RE = re.compile(
    r"^(?P<prefix>\s*STOCK_LIST\s*=\s*)(?P<value>.*?)(?P<suffix>\s*)$"
)


class ConfigService:
    """
    é…ç½®ç®¡ç†æœåŠ¡
    
    è´Ÿè´£ .env æ–‡ä»¶ä¸­ STOCK_LIST çš„è¯»å†™æ“ä½œ
    """
    
    def __init__(self, env_path: Optional[str] = None):
        self.env_path = env_path or _ENV_PATH
    
    def read_env_text(self) -> str:
        """è¯»å– .env æ–‡ä»¶å†…å®¹"""
        try:
            with open(self.env_path, "r", encoding="utf-8") as f:
                return f.read()
        except FileNotFoundError:
            return ""
    
    def write_env_text(self, text: str) -> None:
        """å†™å…¥ .env æ–‡ä»¶å†…å®¹"""
        with open(self.env_path, "w", encoding="utf-8") as f:
            f.write(text)
    
    def get_stock_list(self) -> str:
        """è·å–å½“å‰è‡ªé€‰è‚¡åˆ—è¡¨å­—ç¬¦ä¸²"""
        env_text = self.read_env_text()
        return self._extract_stock_list(env_text)
    
    def set_stock_list(self, stock_list: str) -> str:
        """
        è®¾ç½®è‡ªé€‰è‚¡åˆ—è¡¨
        
        Args:
            stock_list: è‚¡ç¥¨ä»£ç å­—ç¬¦ä¸²ï¼ˆé€—å·æˆ–æ¢è¡Œåˆ†éš”ï¼‰
            
        Returns:
            è§„èŒƒåŒ–åçš„è‚¡ç¥¨åˆ—è¡¨å­—ç¬¦ä¸²
        """
        env_text = self.read_env_text()
        normalized = self._normalize_stock_list(stock_list)
        updated = self._update_stock_list(env_text, normalized)
        self.write_env_text(updated)
        return normalized
    
    def get_env_filename(self) -> str:
        """è·å– .env æ–‡ä»¶å"""
        return os.path.basename(self.env_path)
    
    def _extract_stock_list(self, env_text: str) -> str:
        """ä»ç¯å¢ƒæ–‡ä»¶ä¸­æå– STOCK_LIST å€¼"""
        for line in env_text.splitlines():
            m = _STOCK_LIST_RE.match(line)
            if m:
                raw = m.group("value").strip()
                # å»é™¤å¼•å·
                if (raw.startswith('"') and raw.endswith('"')) or \
                   (raw.startswith("'") and raw.endswith("'")):
                    raw = raw[1:-1]
                return raw
        return ""
    
    def _normalize_stock_list(self, value: str) -> str:
        """è§„èŒƒåŒ–è‚¡ç¥¨åˆ—è¡¨æ ¼å¼"""
        parts = [p.strip() for p in value.replace("\n", ",").split(",")]
        parts = [p for p in parts if p]
        return ",".join(parts)
    
    def _update_stock_list(self, env_text: str, new_value: str) -> str:
        """æ›´æ–°ç¯å¢ƒæ–‡ä»¶ä¸­çš„ STOCK_LIST"""
        lines = env_text.splitlines(keepends=False)
        out_lines: List[str] = []
        replaced = False
        
        for line in lines:
            m = _STOCK_LIST_RE.match(line)
            if not m:
                out_lines.append(line)
                continue
            
            out_lines.append(f"{m.group('prefix')}{new_value}{m.group('suffix')}")
            replaced = True
        
        if not replaced:
            if out_lines and out_lines[-1].strip() != "":
                out_lines.append("")
            out_lines.append(f"STOCK_LIST={new_value}")
        
        trailing_newline = env_text.endswith("\n") if env_text else True
        out = "\n".join(out_lines)
        return out + ("\n" if trailing_newline else "")


# ============================================================
# åˆ†æä»»åŠ¡æœåŠ¡
# ============================================================

class AnalysisService:
    """
    åˆ†æä»»åŠ¡æœåŠ¡
    
    è´Ÿè´£ï¼š
    1. ç®¡ç†å¼‚æ­¥åˆ†æä»»åŠ¡
    2. æ‰§è¡Œè‚¡ç¥¨åˆ†æ
    3. è§¦å‘é€šçŸ¥æ¨é€
    """
    
    _instance: Optional['AnalysisService'] = None
    _lock = threading.Lock()
    
    def __init__(self, max_workers: int = 3):
        self._executor: Optional[ThreadPoolExecutor] = None
        self._max_workers = max_workers
        self._tasks: Dict[str, Dict[str, Any]] = {}
        self._tasks_lock = threading.Lock()
    
    @classmethod
    def get_instance(cls) -> 'AnalysisService':
        """è·å–å•ä¾‹å®ä¾‹"""
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = cls()
        return cls._instance
    
    @property
    def executor(self) -> ThreadPoolExecutor:
        """è·å–æˆ–åˆ›å»ºçº¿ç¨‹æ± """
        if self._executor is None:
            self._executor = ThreadPoolExecutor(
                max_workers=self._max_workers,
                thread_name_prefix="analysis_"
            )
        return self._executor
    
    def submit_analysis(
        self, 
        code: str, 
        report_type: Union[ReportType, str] = ReportType.SIMPLE,
        source_message: Optional[BotMessage] = None
    ) -> Dict[str, Any]:
        """
        æäº¤å¼‚æ­¥åˆ†æä»»åŠ¡
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            report_type: æŠ¥å‘Šç±»å‹æšä¸¾
            
        Returns:
            ä»»åŠ¡ä¿¡æ¯å­—å…¸
        """
        # ç¡®ä¿ report_type æ˜¯æšä¸¾ç±»å‹
        if isinstance(report_type, str):
            report_type = ReportType.from_str(report_type)
        
        task_id = f"{code}_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}"
        
        # æäº¤åˆ°çº¿ç¨‹æ± 
        self.executor.submit(self._run_analysis, code, task_id, report_type, source_message)
        
        logger.info(f"[AnalysisService] å·²æäº¤è‚¡ç¥¨ {code} çš„åˆ†æä»»åŠ¡, task_id={task_id}, report_type={report_type.value}")
        
        return {
            "success": True,
            "message": "åˆ†æä»»åŠ¡å·²æäº¤ï¼Œå°†å¼‚æ­¥æ‰§è¡Œå¹¶æ¨é€é€šçŸ¥",
            "code": code,
            "task_id": task_id,
            "report_type": report_type.value
        }
    
    def get_task_status(self, task_id: str) -> Optional[Dict[str, Any]]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        with self._tasks_lock:
            return self._tasks.get(task_id)
    
    def list_tasks(self, limit: int = 20) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæœ€è¿‘çš„ä»»åŠ¡"""
        with self._tasks_lock:
            tasks = list(self._tasks.values())
        # æŒ‰å¼€å§‹æ—¶é—´å€’åº
        tasks.sort(key=lambda x: x.get('start_time', ''), reverse=True)
        return tasks[:limit]
    
    def _run_analysis(
        self, 
        code: str, 
        task_id: str, 
        report_type: ReportType = ReportType.SIMPLE,
        source_message: Optional[BotMessage] = None
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•åªè‚¡ç¥¨åˆ†æ
        
        å†…éƒ¨æ–¹æ³•ï¼Œåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ
        
        Args:
            code: è‚¡ç¥¨ä»£ç 
            task_id: ä»»åŠ¡ID
            report_type: æŠ¥å‘Šç±»å‹æšä¸¾
        """
        # åˆå§‹åŒ–ä»»åŠ¡çŠ¶æ€
        with self._tasks_lock:
            self._tasks[task_id] = {
                "task_id": task_id,
                "code": code,
                "status": "running",
                "start_time": datetime.now().isoformat(),
                "result": None,
                "error": None,
                "report_type": report_type.value
            }
        
        try:
            # å»¶è¿Ÿå¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
            from src.config import get_config
            from main import StockAnalysisPipeline
            
            logger.info(f"[AnalysisService] å¼€å§‹åˆ†æè‚¡ç¥¨: {code}")
            
            # åˆ›å»ºåˆ†æç®¡é“
            config = get_config()
            pipeline = StockAnalysisPipeline(
                config=config,
                max_workers=1,
                source_message=source_message
            )
            
            # æ‰§è¡Œå•åªè‚¡ç¥¨åˆ†æï¼ˆå¯ç”¨å•è‚¡æ¨é€ï¼‰
            result = pipeline.process_single_stock(
                code=code,
                skip_analysis=False,
                single_stock_notify=True,
                report_type=report_type
            )
            
            if result:
                result_data = {
                    "code": result.code,
                    "name": result.name,
                    "sentiment_score": result.sentiment_score,
                    "operation_advice": result.operation_advice,
                    "trend_prediction": result.trend_prediction,
                    "analysis_summary": result.analysis_summary,
                }
                
                with self._tasks_lock:
                    self._tasks[task_id].update({
                        "status": "completed",
                        "end_time": datetime.now().isoformat(),
                        "result": result_data
                    })
                
                logger.info(f"[AnalysisService] è‚¡ç¥¨ {code} åˆ†æå®Œæˆ: {result.operation_advice}")
                return {"success": True, "task_id": task_id, "result": result_data}
            else:
                with self._tasks_lock:
                    self._tasks[task_id].update({
                        "status": "failed",
                        "end_time": datetime.now().isoformat(),
                        "error": "åˆ†æè¿”å›ç©ºç»“æœ"
                    })
                
                logger.warning(f"[AnalysisService] è‚¡ç¥¨ {code} åˆ†æå¤±è´¥: è¿”å›ç©ºç»“æœ")
                return {"success": False, "task_id": task_id, "error": "åˆ†æè¿”å›ç©ºç»“æœ"}
                
        except Exception as e:
            error_msg = str(e)
            logger.error(f"[AnalysisService] è‚¡ç¥¨ {code} åˆ†æå¼‚å¸¸: {error_msg}")
            
            with self._tasks_lock:
                self._tasks[task_id].update({
                    "status": "failed",
                    "end_time": datetime.now().isoformat(),
                    "error": error_msg
                })
            
            return {"success": False, "task_id": task_id, "error": error_msg}


# ============================================================
# å†å²æŠ¥å‘ŠæœåŠ¡
# ============================================================

import os
import re
import json
from pathlib import Path
from datetime import datetime, date
from typing import List, Dict, Any, Optional, Tuple


class HistoryReportService:
    """
    å†å²æŠ¥å‘ŠæœåŠ¡
    
    è´Ÿè´£ï¼š
    1. ä» reports ç›®å½•è¯»å–å·²ç”Ÿæˆçš„æŠ¥å‘Šæ–‡ä»¶
    2. è§£ææŠ¥å‘Šå†…å®¹ï¼Œæå–ç»“æ„åŒ–æ•°æ®
    3. æä¾›æŒ‰æ—¥æœŸæŸ¥è¯¢æŠ¥å‘Šæ¥å£
    """
    
    def __init__(self, reports_dir: Optional[str] = None):
        """
        åˆå§‹åŒ–å†å²æŠ¥å‘ŠæœåŠ¡
        
        Args:
            reports_dir: æŠ¥å‘Šç›®å½•è·¯å¾„ï¼ˆé»˜è®¤é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ reportsï¼‰
        """
        if reports_dir:
            self.reports_dir = Path(reports_dir)
        else:
            # é»˜è®¤ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ reports
            self.reports_dir = Path(__file__).parent.parent / 'reports'
    
    def get_available_dates(self) -> List[str]:
        """
        è·å–æ‰€æœ‰å¯ç”¨çš„æŠ¥å‘Šæ—¥æœŸåˆ—è¡¨
        
        Returns:
            æ—¥æœŸå­—ç¬¦ä¸²åˆ—è¡¨ï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼ŒæŒ‰æ—¥æœŸé™åºæ’åˆ—
        """
        dates = set()
        
        if not self.reports_dir.exists():
            return []
        
        # åŒ¹é… report_YYYYMMDD.md å’Œ market_review_YYYYMMDD.md æ–‡ä»¶
        report_pattern = re.compile(r'report_(\d{8})\.md')
        market_pattern = re.compile(r'market_review_(\d{8})\.md')
        
        for file in self.reports_dir.iterdir():
            if file.is_file():
                # æ£€æŸ¥ä¸ªè‚¡æŠ¥å‘Š
                match = report_pattern.match(file.name)
                if match:
                    date_str = match.group(1)
                    formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
                    dates.add(formatted_date)
                    continue
                
                # æ£€æŸ¥å¤§ç›˜å¤ç›˜æŠ¥å‘Š
                match = market_pattern.match(file.name)
                if match:
                    date_str = match.group(1)
                    formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
                    dates.add(formatted_date)
        
        # æŒ‰æ—¥æœŸé™åºæ’åˆ—
        return sorted(list(dates), reverse=True)
    
    def get_report_by_date(self, target_date: str) -> Optional[Dict[str, Any]]:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„å®Œæ•´æŠ¥å‘Šæ•°æ®
        
        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            
        Returns:
            æŠ¥å‘Šæ•°æ®å­—å…¸ï¼ŒåŒ…å« marketReview å’Œ decisions
        """
        # è½¬æ¢æ—¥æœŸæ ¼å¼
        date_obj = datetime.strptime(target_date, '%Y-%m-%d')
        date_str_compact = date_obj.strftime('%Y%m%d')
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        report_file = self.reports_dir / f'report_{date_str_compact}.md'
        market_file = self.reports_dir / f'market_review_{date_str_compact}.md'
        
        result = {
            'date': target_date,
            'marketReview': None,
            'decisions': []
        }
        
        # è¯»å–å¤§ç›˜å¤ç›˜
        if market_file.exists():
            result['marketReview'] = self._parse_market_review(market_file.read_text(encoding='utf-8'))
        
        # è¯»å–ä¸ªè‚¡å†³ç­–æŠ¥å‘Š
        if report_file.exists():
            result['decisions'] = self._parse_stock_report(report_file.read_text(encoding='utf-8'))
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•æŠ¥å‘Šæ•°æ®ï¼Œè¿”å› None
        if result['marketReview'] is None and not result['decisions']:
            return None
        
        return result
    
    def _parse_market_review(self, content: str) -> Optional[Dict[str, str]]:
        """
        è§£æå¤§ç›˜å¤ç›˜æŠ¥å‘Šå†…å®¹
        
        Args:
            content: Markdown æ ¼å¼çš„æŠ¥å‘Šå†…å®¹
            
        Returns:
            è§£æåçš„å¸‚åœºå¤ç›˜æ•°æ®
        """
        sections = {
            'summary': '',
            'indexComment': '',
            'capitalFlow': '',
            'hotTopics': '',
            'outlook': '',
            'riskWarning': ''
        }
        
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æå–å„éƒ¨åˆ†å†…å®¹
        # å¸‚åœºæ€»ç»“ - ä¸€ã€å¸‚åœºæ€»ç»“
        summary_match = re.search(r'### ä¸€ã€å¸‚åœºæ€»ç»“\s*\n([^#]+?)(?=###|$)', content)
        if summary_match:
            sections['summary'] = summary_match.group(1).strip()
        
        # æŒ‡æ•°ç‚¹è¯„ - äºŒã€æŒ‡æ•°ç‚¹è¯„
        index_match = re.search(r'### äºŒã€æŒ‡æ•°ç‚¹è¯„\s*\n([^#]+?)(?=###|$)', content)
        if index_match:
            sections['indexComment'] = index_match.group(1).strip()
        
        # èµ„é‡‘åŠ¨å‘ - ä¸‰ã€èµ„é‡‘åŠ¨å‘
        capital_match = re.search(r'### ä¸‰ã€èµ„é‡‘åŠ¨å‘\s*\n([^#]+?)(?=###|$)', content)
        if capital_match:
            sections['capitalFlow'] = capital_match.group(1).strip()
        
        # çƒ­ç‚¹è§£è¯» - å››ã€çƒ­ç‚¹è§£è¯»
        hot_match = re.search(r'### å››ã€çƒ­ç‚¹è§£è¯»\s*\n([^#]+?)(?=###|$)', content)
        if hot_match:
            sections['hotTopics'] = hot_match.group(1).strip()
        
        # åå¸‚å±•æœ› - äº”ã€åå¸‚å±•æœ›
        outlook_match = re.search(r'### äº”ã€åå¸‚å±•æœ›\s*\n([^#]+?)(?=###|$)', content)
        if outlook_match:
            sections['outlook'] = outlook_match.group(1).strip()
        
        # é£é™©æç¤º - å…­ã€é£é™©æç¤º
        risk_match = re.search(r'### å…­ã€é£é™©æç¤º\s*\n([^#]+?)(?=###|$)', content)
        if risk_match:
            sections['riskWarning'] = risk_match.group(1).strip()
        
        return sections if any(sections.values()) else None
    
    def _parse_stock_report(self, content: str) -> List[Dict[str, Any]]:
        """
        è§£æä¸ªè‚¡åˆ†ææŠ¥å‘Šå†…å®¹
        
        Args:
            content: Markdown æ ¼å¼çš„æŠ¥å‘Šå†…å®¹
            
        Returns:
            ä¸ªè‚¡å†³ç­–åˆ—è¡¨
        """
        decisions = []
        
        # æå–æŠ¥å‘Šæ‘˜è¦ä¸­çš„ç»Ÿè®¡ä¿¡æ¯
        summary_match = re.search(r'> å…±åˆ†æ \*\*(\d+)\*\* åª.*ğŸŸ¢ä¹°å…¥:(\d+).*ğŸŸ¡è§‚æœ›:(\d+).*ğŸ”´å–å‡º:(\d+)', content)
        
        # ä½¿ç”¨finditeræ‰¾åˆ°æ‰€æœ‰è‚¡ç¥¨éƒ¨åˆ†
        # æ¨¡å¼ï¼š## [emoji] è‚¡ç¥¨åç§° (ä»£ç )
        # æ³¨æ„ï¼šè‚¡ç¥¨åç§°ä¸­å¯èƒ½åŒ…å«ç©ºæ ¼ï¼Œä»£ç åœ¨æ‹¬å·ä¸­
        # åŒ¹é…åˆ°è¡Œå°¾ï¼Œä½¿ç”¨å¤šè¡Œæ¨¡å¼
        stock_pattern = r'^##\s+([ğŸ’šâšªğŸ”´])\s+(.+)$'
        
        matches = list(re.finditer(stock_pattern, content, re.MULTILINE))
        
        for i, match in enumerate(matches):
            emoji = match.group(1)
            header_line = match.group(2).strip()
            
            # æå–è‚¡ç¥¨åç§°å’Œä»£ç 
            # header_line æ ¼å¼: "è‚¡ç¥¨åç§° (ä»£ç )" æˆ– "è‚¡ç¥¨åç§°(ä»£ç )"
            # ä»å³å¾€å·¦æ‰¾æœ€åä¸€ä¸ªæ‹¬å·ï¼Œé¿å…è‚¡ç¥¨åç§°ä¸­æœ‰æ‹¬å·
            if '(' in header_line and ')' in header_line:
                # æ‰¾åˆ°æœ€åä¸€ä¸ª '(' å’Œå¯¹åº”çš„ ')'
                code_start = header_line.rfind('(')
                code_end = header_line.rfind(')')
                if code_start < code_end:
                    name = header_line[:code_start].strip()
                    code = header_line[code_start + 1:code_end].strip()
                else:
                    continue
            else:
                continue
            
            # è·å–è¯¥è‚¡ç¥¨çš„å†…å®¹ï¼ˆä»å½“å‰åŒ¹é…ä½ç½®åˆ°ä¸‹ä¸€ä¸ªåŒ¹é…ä½ç½®æˆ–æ–‡ä»¶ç»“æŸï¼‰
            start_pos = match.end()
            if i + 1 < len(matches):
                section_content = content[start_pos:matches[i + 1].start()]
            else:
                section_content = content[start_pos:]
            
            decision = self._parse_single_stock_content(name, code, emoji, section_content)
            if decision:
                decisions.append(decision)
        
        return decisions
    
    def _parse_single_stock_content(self, name: str, code: str, signal_emoji: str, section: str) -> Optional[Dict[str, Any]]:
        """
        è§£æå•ä¸ªè‚¡ç¥¨çš„åˆ†æå†…å®¹
        
        Args:
            name: è‚¡ç¥¨åç§°
            code: è‚¡ç¥¨ä»£ç 
            signal_emoji: ä¿¡å·emojiï¼ˆğŸ’šä¹°å…¥/âšªè§‚æœ›/ğŸ”´å–å‡ºï¼‰
            section: å•ä¸ªè‚¡ç¥¨çš„åˆ†æå†…å®¹
            
        Returns:
            è§£æåçš„è‚¡ç¥¨å†³ç­–æ•°æ®
        """
        
        # æ ¹æ® emoji åˆ¤æ–­ä¿¡å·ç±»å‹
        signal_map = {
            'ğŸ’š': 'buy',
            'âšª': 'watch',
            'ğŸ”´': 'sell'
        }
        signal = signal_map.get(signal_emoji, 'watch')
        
        # æå–è¯„åˆ†
        score_match = re.search(r'è¯„åˆ†[:\s]*(\d+)', section)
        score = int(score_match.group(1)) if score_match else 50
        
        # æå–å½“å‰ä»·
        price_match = re.search(r'å½“å‰ä»·\s*\|\s*([\d.]+)', section)
        price = float(price_match.group(1)) if price_match else 0.0
        
        # æå–ä¹–ç¦»ç‡
        bias_match = re.search(r'ä¹–ç¦»ç‡\([^)]+\)\s*\|\s*([+-]?[\d.]+)%', section)
        bias = float(bias_match.group(1)) if bias_match else 0.0
        
        # æå–è¶‹åŠ¿å¼ºåº¦
        trend_match = re.search(r'è¶‹åŠ¿å¼ºåº¦[:\s]*(\d+)', section)
        trend = int(trend_match.group(1)) if trend_match else 50
        
        # æå–å†³ç­–æŒ‡ä»¤ï¼ˆä¸€å¥è¯å†³ç­–ï¼‰
        decision_match = re.search(r'> \*\*ä¸€å¥è¯å†³ç­–\*\*[:ï¼š]\s*([^\n]+)', section)
        if not decision_match:
            decision_match = re.search(r'ä¸€å¥è¯å†³ç­–[:\s]*([^\n]+)', section)
        decision = decision_match.group(1).strip() if decision_match else ''
        
        # æå–åŸºæœ¬é¢è¦ç‚¹
        fundamentals = []
        # ä»é‡è¦ä¿¡æ¯é€Ÿè§ˆä¸­æå–
        sentiment_match = re.search(r'\*\*ğŸ’­ èˆ†æƒ…æƒ…ç»ª\*\*[:ï¼š]\s*([^\n]+)', section)
        if sentiment_match:
            fundamentals.append(f"èˆ†æƒ…: {sentiment_match.group(1).strip()}")
        
        expectation_match = re.search(r'\*\*ğŸ“Š ä¸šç»©é¢„æœŸ\*\*[:ï¼š]\s*([^\n]+)', section)
        if expectation_match:
            fundamentals.append(f"ä¸šç»©: {expectation_match.group(1).strip()}")
        
        # æå–æœ€æ–°åŠ¨æ€
        news_match = re.search(r'\*\*ğŸ“¢ æœ€æ–°åŠ¨æ€\*\*[:ï¼š]\s*([^\n]+)', section)
        if news_match:
            fundamentals.append(f"åŠ¨æ€: {news_match.group(1).strip()}")
        
        # å¦‚æœæ²¡æœ‰æå–åˆ°åŸºæœ¬é¢ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤ä¿¡æ¯
        if not fundamentals:
            fundamentals = ['æš‚æ— è¯¦ç»†åŸºæœ¬é¢æ•°æ®']
        
        # æå–æ“ä½œå»ºè®®ï¼ˆç©ºä»“è€…å»ºè®®ï¼‰
        suggestion_match = re.search(r'\| ğŸ†• \*\*ç©ºä»“è€…\*\* \|\s*([^\|]+?)\s*\|', section)
        if not suggestion_match:
            suggestion_match = re.search(r'ç©ºä»“è€….*å»ºè®®[:ï¼š]\s*([^\n]+)', section)
        suggestion = suggestion_match.group(1).strip() if suggestion_match else 'å»ºè®®è§‚æœ›ï¼Œç­‰å¾…æœºä¼šã€‚'
        
        return {
            'code': code,
            'name': name,
            'signal': signal,
            'score': score,
            'price': price,
            'bias': bias,
            'trend': trend,
            'decision': decision,
            'fundamentals': fundamentals,
            'suggestion': suggestion
        }


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

def get_config_service() -> ConfigService:
    """è·å–é…ç½®æœåŠ¡å®ä¾‹"""
    return ConfigService()


def get_analysis_service() -> AnalysisService:
    """è·å–åˆ†ææœåŠ¡å•ä¾‹"""
    return AnalysisService.get_instance()


def get_history_report_service() -> HistoryReportService:
    """è·å–å†å²æŠ¥å‘ŠæœåŠ¡å®ä¾‹"""
    return HistoryReportService()
