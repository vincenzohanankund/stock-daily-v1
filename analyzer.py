# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé¸è‚¡æ™ºèƒ½åˆ†æç³»çµ± - AIåˆ†æå±¤
===================================

è·è²¬ï¼š
1. å°è£ Gemini API èª¿ç”¨é‚è¼¯
2. åˆ©ç”¨ Google Search Grounding ç²å–å¯¦æ™‚æ–°è
3. çµåˆæŠ€è¡“é¢å’Œæ¶ˆæ¯é¢ç”Ÿæˆåˆ†æå ±å‘Š
"""

import json
import logging
import time
from dataclasses import dataclass
from typing import Optional, Dict, Any, List

from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log,
)

from config import get_config

logger = logging.getLogger(__name__)


# è‚¡ç¥¨åç¨±æ˜ å°„ï¼ˆå¸¸è¦‹è‚¡ç¥¨ï¼‰
STOCK_NAME_MAP = {
    '600519': 'è²´å·èŒ…è‡º',
    '000001': 'å¹³å®‰éŠ€è¡Œ',
    '300750': 'å¯§å¾·æ™‚ä»£',
    '002594': 'æ¯”äºè¿ª',
    '600036': 'æ‹›å•†éŠ€è¡Œ',
    '601318': 'ä¸­åœ‹å¹³å®‰',
    '000858': 'äº”ç³§æ¶²',
    '600276': 'æ†ç‘é†«è—¥',
    '601012': 'éš†åŸºç¶ èƒ½',
    '002475': 'ç«‹è¨Šç²¾å¯†',
    '300059': 'æ±æ–¹è²¡å¯Œ',
    '002415': 'æµ·åº·å¨è¦–',
    '600900': 'é•·æ±Ÿé›»åŠ›',
    '601166': 'èˆˆæ¥­éŠ€è¡Œ',
    '600028': 'ä¸­åœ‹çŸ³åŒ–',
}


@dataclass
class AnalysisResult:
    """
    AI åˆ†æçµæœæ•¸æ“šé¡ - æ±ºç­–å„€è¡¨ç›¤ç‰ˆ
    
    å°è£ Gemini è¿”å›çš„åˆ†æçµæœï¼ŒåŒ…å«æ±ºç­–å„€è¡¨ç›¤å’Œè©³ç´°åˆ†æ
    """
    code: str
    name: str
    
    # ========== æ ¸å¿ƒæŒ‡æ¨™ ==========
    sentiment_score: int  # ç¶œåˆè©•åˆ† 0-100 (>70å¼·çƒˆçœ‹å¤š, >60çœ‹å¤š, 40-60éœ‡ç›ª, <40çœ‹ç©º)
    trend_prediction: str  # è¶¨å‹¢é æ¸¬ï¼šå¼·çƒˆçœ‹å¤š/çœ‹å¤š/éœ‡ç›ª/çœ‹ç©º/å¼·çƒˆçœ‹ç©º
    operation_advice: str  # æ“ä½œå»ºè­°ï¼šè²·å…¥/åŠ å€‰/æŒæœ‰/æ¸›å€‰/è³£å‡º/è§€æœ›
    confidence_level: str = "ä¸­"  # ç½®ä¿¡åº¦ï¼šé«˜/ä¸­/ä½
    
    # ========== æ±ºç­–å„€è¡¨ç›¤ (æ–°å¢) ==========
    dashboard: Optional[Dict[str, Any]] = None  # å®Œæ•´çš„æ±ºç­–å„€è¡¨ç›¤æ•¸æ“š
    
    # ========== èµ°å‹¢åˆ†æ ==========
    trend_analysis: str = ""  # èµ°å‹¢å½¢æ…‹åˆ†æï¼ˆæ”¯æ’ä½ã€å£“åŠ›ä½ã€è¶¨å‹¢ç·šç­‰ï¼‰
    short_term_outlook: str = ""  # çŸ­æœŸå±•æœ›ï¼ˆ1-3æ—¥ï¼‰
    medium_term_outlook: str = ""  # ä¸­æœŸå±•æœ›ï¼ˆ1-2å‘¨ï¼‰
    
    # ========== æŠ€è¡“é¢åˆ†æ ==========
    technical_analysis: str = ""  # æŠ€è¡“æŒ‡æ¨™ç¶œåˆåˆ†æ
    ma_analysis: str = ""  # å‡ç·šåˆ†æï¼ˆå¤šé ­/ç©ºé ­æ’åˆ—ï¼Œé‡‘å‰/æ­»å‰ç­‰ï¼‰
    volume_analysis: str = ""  # é‡èƒ½åˆ†æï¼ˆæ”¾é‡/ç¸®é‡ï¼Œä¸»åŠ›å‹•å‘ç­‰ï¼‰
    pattern_analysis: str = ""  # Kç·šå½¢æ…‹åˆ†æ
    
    # ========== åŸºæœ¬é¢åˆ†æ ==========
    fundamental_analysis: str = ""  # åŸºæœ¬é¢ç¶œåˆåˆ†æ
    sector_position: str = ""  # æ¿å¡Šåœ°ä½å’Œè¡Œæ¥­è¶¨å‹¢
    company_highlights: str = ""  # å…¬å¸äº®é»/é¢¨éšªé»
    
    # ========== æƒ…ç·’é¢/æ¶ˆæ¯é¢åˆ†æ ==========
    news_summary: str = ""  # è¿‘æœŸé‡è¦æ–°è/å…¬å‘Šæ‘˜è¦
    market_sentiment: str = ""  # å¸‚å ´æƒ…ç·’åˆ†æ
    hot_topics: str = ""  # ç›¸é—œç†±é»è©±é¡Œ
    
    # ========== ç¶œåˆåˆ†æ ==========
    analysis_summary: str = ""  # ç¶œåˆåˆ†ææ‘˜è¦
    key_points: str = ""  # æ ¸å¿ƒçœ‹é»ï¼ˆ3-5å€‹è¦é»ï¼‰
    risk_warning: str = ""  # é¢¨éšªæç¤º
    buy_reason: str = ""  # è²·å…¥/è³£å‡ºç†ç”±
    
    # ========== å…ƒæ•¸æ“š ==========
    raw_response: Optional[str] = None  # åŸå§‹éŸ¿æ‡‰ï¼ˆèª¿è©¦ç”¨ï¼‰
    search_performed: bool = False  # æ˜¯å¦åŸ·è¡Œäº†è¯ç¶²æœç´¢
    data_sources: str = ""  # æ•¸æ“šä¾†æºèªªæ˜
    success: bool = True
    error_message: Optional[str] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºå­—å…¸"""
        return {
            'code': self.code,
            'name': self.name,
            'sentiment_score': self.sentiment_score,
            'trend_prediction': self.trend_prediction,
            'operation_advice': self.operation_advice,
            'confidence_level': self.confidence_level,
            'dashboard': self.dashboard,  # æ±ºç­–å„€è¡¨ç›¤æ•¸æ“š
            'trend_analysis': self.trend_analysis,
            'short_term_outlook': self.short_term_outlook,
            'medium_term_outlook': self.medium_term_outlook,
            'technical_analysis': self.technical_analysis,
            'ma_analysis': self.ma_analysis,
            'volume_analysis': self.volume_analysis,
            'pattern_analysis': self.pattern_analysis,
            'fundamental_analysis': self.fundamental_analysis,
            'sector_position': self.sector_position,
            'company_highlights': self.company_highlights,
            'news_summary': self.news_summary,
            'market_sentiment': self.market_sentiment,
            'hot_topics': self.hot_topics,
            'analysis_summary': self.analysis_summary,
            'key_points': self.key_points,
            'risk_warning': self.risk_warning,
            'buy_reason': self.buy_reason,
            'search_performed': self.search_performed,
            'success': self.success,
            'error_message': self.error_message,
        }
    
    def get_core_conclusion(self) -> str:
        """ç²å–æ ¸å¿ƒçµè«–ï¼ˆä¸€å¥è©±ï¼‰"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            return self.dashboard['core_conclusion'].get('one_sentence', self.analysis_summary)
        return self.analysis_summary
    
    def get_position_advice(self, has_position: bool = False) -> str:
        """ç²å–æŒå€‰å»ºè­°"""
        if self.dashboard and 'core_conclusion' in self.dashboard:
            pos_advice = self.dashboard['core_conclusion'].get('position_advice', {})
            if has_position:
                return pos_advice.get('has_position', self.operation_advice)
            return pos_advice.get('no_position', self.operation_advice)
        return self.operation_advice
    
    def get_sniper_points(self) -> Dict[str, str]:
        """ç²å–ç‹™æ“Šé»ä½"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('sniper_points', {})
        return {}
    
    def get_checklist(self) -> List[str]:
        """ç²å–æª¢æŸ¥æ¸…å–®"""
        if self.dashboard and 'battle_plan' in self.dashboard:
            return self.dashboard['battle_plan'].get('action_checklist', [])
        return []
    
    def get_risk_alerts(self) -> List[str]:
        """ç²å–é¢¨éšªè­¦å ±"""
        if self.dashboard and 'intelligence' in self.dashboard:
            return self.dashboard['intelligence'].get('risk_alerts', [])
        return []
    
    def get_emoji(self) -> str:
        """æ ¹æ“šæ“ä½œå»ºè­°è¿”å›å°æ‡‰ emoji"""
        emoji_map = {
            'è²·å…¥': 'ğŸŸ¢',
            'åŠ å€‰': 'ğŸŸ¢',
            'å¼·çƒˆè²·å…¥': 'ğŸ’š',
            'æŒæœ‰': 'ğŸŸ¡',
            'è§€æœ›': 'âšª',
            'æ¸›å€‰': 'ğŸŸ ',
            'è³£å‡º': 'ğŸ”´',
            'å¼·çƒˆè³£å‡º': 'âŒ',
        }
        return emoji_map.get(self.operation_advice, 'ğŸŸ¡')
    
    def get_confidence_stars(self) -> str:
        """è¿”å›ç½®ä¿¡åº¦æ˜Ÿç´š"""
        star_map = {'é«˜': 'â­â­â­', 'ä¸­': 'â­â­', 'ä½': 'â­'}
        return star_map.get(self.confidence_level, 'â­â­')


class GeminiAnalyzer:
    """
    Gemini AI åˆ†æå™¨
    
    è·è²¬ï¼š
    1. èª¿ç”¨ Google Gemini API é€²è¡Œè‚¡ç¥¨åˆ†æ
    2. çµåˆé å…ˆæœç´¢çš„æ–°èå’ŒæŠ€è¡“é¢æ•¸æ“šç”Ÿæˆåˆ†æå ±å‘Š
    3. è§£æ AI è¿”å›çš„ JSON æ ¼å¼çµæœ
    
    ä½¿ç”¨æ–¹å¼ï¼š
        analyzer = GeminiAnalyzer()
        result = analyzer.analyze(context, news_context)
    """
    
    # ========================================
    # ç³»çµ±æç¤ºè© - æ±ºç­–å„€è¡¨ç›¤ v2.0
    # ========================================
    # è¼¸å‡ºæ ¼å¼å‡ç´šï¼šå¾ç°¡å–®ä¿¡è™Ÿå‡ç´šç‚ºæ±ºç­–å„€è¡¨ç›¤
    # æ ¸å¿ƒæ¨¡å¡Šï¼šæ ¸å¿ƒçµè«– + æ•¸æ“šé€è¦– + è¼¿æƒ…æƒ…å ± + ä½œæˆ°è¨ˆåŠƒ
    # ========================================
    
    SYSTEM_PROMPT = """ä½ æ˜¯ä¸€ä½å°ˆæ³¨æ–¼è¶¨å‹¢äº¤æ˜“çš„ A è‚¡æŠ•è³‡åˆ†æå¸«ï¼Œè² è²¬ç”Ÿæˆå°ˆæ¥­çš„ã€æ±ºç­–å„€è¡¨ç›¤ã€‘åˆ†æå ±å‘Šã€‚

## æ ¸å¿ƒäº¤æ˜“ç†å¿µï¼ˆå¿…é ˆåš´æ ¼éµå®ˆï¼‰

### 1. åš´é€²ç­–ç•¥ï¼ˆä¸è¿½é«˜ï¼‰
- **çµ•å°ä¸è¿½é«˜**ï¼šç•¶è‚¡åƒ¹åé›¢ MA5 è¶…é 5% æ™‚ï¼Œå …æ±ºä¸è²·å…¥
- **ä¹–é›¢ç‡å…¬å¼**ï¼š(ç¾åƒ¹ - MA5) / MA5 Ã— 100%
- ä¹–é›¢ç‡ < 2%ï¼šæœ€ä½³è²·é»å€é–“
- ä¹–é›¢ç‡ 2-5%ï¼šå¯å°å€‰ä»‹å…¥
- ä¹–é›¢ç‡ > 5%ï¼šåš´ç¦è¿½é«˜ï¼ç›´æ¥åˆ¤å®šç‚º"è§€æœ›"

### 2. è¶¨å‹¢äº¤æ˜“ï¼ˆé †å‹¢è€Œç‚ºï¼‰
- **å¤šé ­æ’åˆ—å¿…é ˆæ¢ä»¶**ï¼šMA5 > MA10 > MA20
- åªåšå¤šé ­æ’åˆ—çš„è‚¡ç¥¨ï¼Œç©ºé ­æ’åˆ—å …æ±ºä¸ç¢°
- å‡ç·šç™¼æ•£ä¸Šè¡Œå„ªæ–¼å‡ç·šç²˜åˆ
- è¶¨å‹¢å¼·åº¦åˆ¤æ–·ï¼šçœ‹å‡ç·šé–“è·æ˜¯å¦åœ¨æ“´å¤§

### 3. æ•ˆç‡å„ªå…ˆï¼ˆç±Œç¢¼çµæ§‹ï¼‰
- é—œæ³¨ç±Œç¢¼é›†ä¸­åº¦ï¼š90%é›†ä¸­åº¦ < 15% è¡¨ç¤ºç±Œç¢¼é›†ä¸­
- ç²åˆ©æ¯”ä¾‹åˆ†æï¼š70-90% ç²åˆ©ç›¤æ™‚éœ€è­¦æƒ•ç²åˆ©å›å
- å¹³å‡æˆæœ¬èˆ‡ç¾åƒ¹é—œä¿‚ï¼šç¾åƒ¹é«˜æ–¼å¹³å‡æˆæœ¬ 5-15% ç‚ºå¥åº·

### 4. è²·é»åå¥½ï¼ˆå›è¸©æ”¯æ’ï¼‰
- **æœ€ä½³è²·é»**ï¼šç¸®é‡å›è¸© MA5 ç²å¾—æ”¯æ’
- **æ¬¡å„ªè²·é»**ï¼šå›è¸© MA10 ç²å¾—æ”¯æ’
- **è§€æœ›æƒ…æ³**ï¼šè·Œç ´ MA20 æ™‚è§€æœ›

### 5. é¢¨éšªæ’æŸ¥é‡é»
- æ¸›æŒå…¬å‘Šï¼ˆè‚¡æ±ã€é«˜ç®¡æ¸›æŒï¼‰
- æ¥­ç¸¾é è™§/å¤§å¹…ä¸‹æ»‘
- ç›£ç®¡è™•ç½°/ç«‹æ¡ˆèª¿æŸ¥
- è¡Œæ¥­æ”¿ç­–åˆ©ç©º
- å¤§é¡è§£ç¦

## è¼¸å‡ºæ ¼å¼ï¼šæ±ºç­–å„€è¡¨ç›¤ JSON

è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¼¸å‡ºï¼Œé€™æ˜¯ä¸€å€‹å®Œæ•´çš„ã€æ±ºç­–å„€è¡¨ç›¤ã€‘ï¼š

```json
{
    "sentiment_score": 0-100æ•´æ•¸,
    "trend_prediction": "å¼·çƒˆçœ‹å¤š/çœ‹å¤š/éœ‡ç›ª/çœ‹ç©º/å¼·çƒˆçœ‹ç©º",
    "operation_advice": "è²·å…¥/åŠ å€‰/æŒæœ‰/æ¸›å€‰/è³£å‡º/è§€æœ›",
    "confidence_level": "é«˜/ä¸­/ä½",
    
    "dashboard": {
        "core_conclusion": {
            "one_sentence": "ä¸€å¥è©±æ ¸å¿ƒçµè«–ï¼ˆ30å­—ä»¥å…§ï¼Œç›´æ¥å‘Šè¨´ç”¨æˆ¶åšä»€éº¼ï¼‰",
            "signal_type": "ğŸŸ¢è²·å…¥ä¿¡è™Ÿ/ğŸŸ¡æŒæœ‰è§€æœ›/ğŸ”´è³£å‡ºä¿¡è™Ÿ/âš ï¸é¢¨éšªè­¦å‘Š",
            "time_sensitivity": "ç«‹å³è¡Œå‹•/ä»Šæ—¥å…§/æœ¬é€±å…§/ä¸æ€¥",
            "position_advice": {
                "no_position": "ç©ºå€‰è€…å»ºè­°ï¼šå…·é«”æ“ä½œæŒ‡å¼•",
                "has_position": "æŒå€‰è€…å»ºè­°ï¼šå…·é«”æ“ä½œæŒ‡å¼•"
            }
        },
        
        "data_perspective": {
            "trend_status": {
                "ma_alignment": "å‡ç·šæ’åˆ—ç‹€æ…‹æè¿°",
                "is_bullish": true/false,
                "trend_score": 0-100
            },
            "price_position": {
                "current_price": ç•¶å‰åƒ¹æ ¼æ•¸å€¼,
                "ma5": MA5æ•¸å€¼,
                "ma10": MA10æ•¸å€¼,
                "ma20": MA20æ•¸å€¼,
                "bias_ma5": ä¹–é›¢ç‡ç™¾åˆ†æ¯”æ•¸å€¼,
                "bias_status": "å®‰å…¨/è­¦æˆ’/å±éšª",
                "support_level": æ”¯æ’ä½åƒ¹æ ¼,
                "resistance_level": å£“åŠ›ä½åƒ¹æ ¼
            },
            "volume_analysis": {
                "volume_ratio": é‡æ¯”æ•¸å€¼,
                "volume_status": "æ”¾é‡/ç¸®é‡/å¹³é‡",
                "turnover_rate": æ›æ‰‹ç‡ç™¾åˆ†æ¯”,
                "volume_meaning": "é‡èƒ½å«ç¾©è§£è®€ï¼ˆå¦‚ï¼šç¸®é‡å›èª¿éŒ¶ç¤ºæ‹‹å£“æ¸›è¼•ï¼‰"
            },
            "chip_structure": {
                "profit_ratio": ç²åˆ©æ¯”ä¾‹,
                "avg_cost": å¹³å‡æˆæœ¬,
                "concentration": ç±Œç¢¼é›†ä¸­åº¦,
                "chip_health": "å¥åº·/ä¸€èˆ¬/è­¦æƒ•"
            }
        },
        
        "intelligence": {
            "latest_news": "ã€æœ€æ–°æ¶ˆæ¯ã€‘è¿‘æœŸé‡è¦æ–°èæ‘˜è¦",
            "risk_alerts": ["é¢¨éšªé»1ï¼šå…·é«”æè¿°", "é¢¨éšªé»2ï¼šå…·é«”æè¿°"],
            "positive_catalysts": ["åˆ©å¥½1ï¼šå…·é«”æè¿°", "åˆ©å¥½2ï¼šå…·é«”æè¿°"],
            "earnings_outlook": "æ¥­ç¸¾é æœŸåˆ†æï¼ˆåŸºæ–¼å¹´å ±é å‘Šã€æ¥­ç¸¾å¿«å ±ç­‰ï¼‰",
            "sentiment_summary": "è¼¿æƒ…æƒ…ç·’ä¸€å¥è©±ç¸½çµ"
        },
        
        "battle_plan": {
            "sniper_points": {
                "ideal_buy": "ç†æƒ³è²·å…¥é»ï¼šXXå…ƒï¼ˆåœ¨MA5é™„è¿‘ï¼‰",
                "secondary_buy": "æ¬¡å„ªè²·å…¥é»ï¼šXXå…ƒï¼ˆåœ¨MA10é™„è¿‘ï¼‰",
                "stop_loss": "æ­¢æä½ï¼šXXå…ƒï¼ˆè·Œç ´MA20æˆ–X%ï¼‰",
                "take_profit": "ç›®æ¨™ä½ï¼šXXå…ƒï¼ˆå‰é«˜/æ•´æ•¸é—œå£ï¼‰"
            },
            "position_strategy": {
                "suggested_position": "å»ºè­°å€‰ä½ï¼šXæˆ",
                "entry_plan": "åˆ†æ‰¹å»ºå€‰ç­–ç•¥æè¿°",
                "risk_control": "é¢¨æ§ç­–ç•¥æè¿°"
            },
            "action_checklist": [
                "âœ…/âš ï¸/âŒ æª¢æŸ¥é …1ï¼šå¤šé ­æ’åˆ—",
                "âœ…/âš ï¸/âŒ æª¢æŸ¥é …2ï¼šä¹–é›¢ç‡<5%",
                "âœ…/âš ï¸/âŒ æª¢æŸ¥é …3ï¼šé‡èƒ½é…åˆ",
                "âœ…/âš ï¸/âŒ æª¢æŸ¥é …4ï¼šç„¡é‡å¤§åˆ©ç©º",
                "âœ…/âš ï¸/âŒ æª¢æŸ¥é …5ï¼šç±Œç¢¼å¥åº·"
            ]
        }
    },
    
    "analysis_summary": "100å­—ç¶œåˆåˆ†ææ‘˜è¦",
    "key_points": "3-5å€‹æ ¸å¿ƒçœ‹é»ï¼Œé€—è™Ÿåˆ†éš”",
    "risk_warning": "é¢¨éšªæç¤º",
    "buy_reason": "æ“ä½œç†ç”±ï¼Œå¼•ç”¨äº¤æ˜“ç†å¿µ",
    
    "trend_analysis": "èµ°å‹¢å½¢æ…‹åˆ†æ",
    "short_term_outlook": "çŸ­æœŸ1-3æ—¥å±•æœ›",
    "medium_term_outlook": "ä¸­æœŸ1-2å‘¨å±•æœ›",
    "technical_analysis": "æŠ€è¡“é¢ç¶œåˆåˆ†æ",
    "ma_analysis": "å‡ç·šç³»çµ±åˆ†æ",
    "volume_analysis": "é‡èƒ½åˆ†æ",
    "pattern_analysis": "Kç·šå½¢æ…‹åˆ†æ",
    "fundamental_analysis": "åŸºæœ¬é¢åˆ†æ",
    "sector_position": "æ¿å¡Šè¡Œæ¥­åˆ†æ",
    "company_highlights": "å…¬å¸äº®é»/é¢¨éšª",
    "news_summary": "æ–°èæ‘˜è¦",
    "market_sentiment": "å¸‚å ´æƒ…ç·’",
    "hot_topics": "ç›¸é—œç†±é»",
    
    "search_performed": true/false,
    "data_sources": "æ•¸æ“šä¾†æºèªªæ˜"
}
```

## è©•åˆ†æ¨™æº–

### å¼·çƒˆè²·å…¥ï¼ˆ80-100åˆ†ï¼‰ï¼š
- âœ… å¤šé ­æ’åˆ—ï¼šMA5 > MA10 > MA20
- âœ… ä½ä¹–é›¢ç‡ï¼š<2%ï¼Œæœ€ä½³è²·é»
- âœ… ç¸®é‡å›èª¿æˆ–æ”¾é‡çªç ´
- âœ… ç±Œç¢¼é›†ä¸­å¥åº·
- âœ… æ¶ˆæ¯é¢æœ‰åˆ©å¥½å‚¬åŒ–

### è²·å…¥ï¼ˆ60-79åˆ†ï¼‰ï¼š
- âœ… å¤šé ­æ’åˆ—æˆ–å¼±å‹¢å¤šé ­
- âœ… ä¹–é›¢ç‡ <5%
- âœ… é‡èƒ½æ­£å¸¸
- âšª å…è¨±ä¸€é …æ¬¡è¦æ¢ä»¶ä¸æ»¿è¶³

### è§€æœ›ï¼ˆ40-59åˆ†ï¼‰ï¼š
- âš ï¸ ä¹–é›¢ç‡ >5%ï¼ˆè¿½é«˜é¢¨éšªï¼‰
- âš ï¸ å‡ç·šçºç¹è¶¨å‹¢ä¸æ˜
- âš ï¸ æœ‰é¢¨éšªäº‹ä»¶

### è³£å‡º/æ¸›å€‰ï¼ˆ0-39åˆ†ï¼‰ï¼š
- âŒ ç©ºé ­æ’åˆ—
- âŒ è·Œç ´MA20
- âŒ æ”¾é‡ä¸‹è·Œ
- âŒ é‡å¤§åˆ©ç©º

## æ±ºç­–å„€è¡¨ç›¤æ ¸å¿ƒåŸå‰‡

1. **æ ¸å¿ƒçµè«–å…ˆè¡Œ**ï¼šä¸€å¥è©±èªªæ¸…è©²è²·è©²è³£
2. **åˆ†æŒå€‰å»ºè­°**ï¼šç©ºå€‰è€…å’ŒæŒå€‰è€…çµ¦ä¸åŒå»ºè­°
3. **ç²¾ç¢ºç‹™æ“Šé»**ï¼šå¿…é ˆçµ¦å‡ºå…·é«”åƒ¹æ ¼ï¼Œä¸èªªæ¨¡ç³Šçš„è©±
4. **æª¢æŸ¥æ¸…å–®å¯è¦–åŒ–**ï¼šç”¨ âœ…âš ï¸âŒ æ˜ç¢ºé¡¯ç¤ºæ¯é …æª¢æŸ¥çµæœ
5. **é¢¨éšªå„ªå…ˆç´š**ï¼šè¼¿æƒ…ä¸­çš„é¢¨éšªé»è¦é†’ç›®æ¨™å‡º"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ– AI åˆ†æå™¨
        
        å„ªå…ˆç´šï¼šGemini > OpenAI å…¼å®¹ API
        
        Args:
            api_key: Gemini API Keyï¼ˆå¯é¸ï¼Œé»˜èªå¾é…ç½®è®€å–ï¼‰
        """
        config = get_config()
        self._api_key = api_key or config.gemini_api_key
        self._model = None
        self._current_model_name = None  # ç•¶å‰ä½¿ç”¨çš„æ¨¡å‹åç¨±
        self._using_fallback = False  # æ˜¯å¦æ­£åœ¨ä½¿ç”¨å‚™é¸æ¨¡å‹
        self._use_openai = False  # æ˜¯å¦ä½¿ç”¨ OpenAI å…¼å®¹ API
        self._openai_client = None  # OpenAI å®¢æˆ¶ç«¯
        
        # æª¢æŸ¥ Gemini API Key æ˜¯å¦æœ‰æ•ˆï¼ˆéæ¿¾ä½”ä½ç¬¦ï¼‰
        gemini_key_valid = self._api_key and not self._api_key.startswith('your_') and len(self._api_key) > 10
        
        # å„ªå…ˆåšè©¦åˆå§‹åŒ– Gemini
        if gemini_key_valid:
            try:
                self._init_model()
            except Exception as e:
                logger.warning(f"Gemini åˆå§‹åŒ–å¤±æ•—: {e}ï¼Œå˜—è©¦ OpenAI å…¼å®¹ API")
                self._init_openai_fallback()
        else:
            # Gemini Key æœªé…ç½®ï¼Œå˜—è©¦ OpenAI
            logger.info("Gemini API Key æœªé…ç½®ï¼Œå˜—è©¦ä½¿ç”¨ OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
        
        # å…©è€…éƒ½æœªé…ç½®
        if not self._model and not self._openai_client:
            logger.warning("æœªé…ç½®ä»»ä½• AI API Keyï¼ŒAI åˆ†æåŠŸèƒ½å°‡ä¸å¯ç”¨")
    
    def _init_openai_fallback(self) -> None:
        """
        åˆå§‹åŒ– OpenAI å…¼å®¹ API ä½œç‚ºå‚™é¸
        
        æ”¯æŒæ‰€æœ‰ OpenAI æ ¼å¼çš„ APIï¼ŒåŒ…æ‹¬ï¼š
        - OpenAI å®˜æ–¹
        - DeepSeek
        - é€šç¾©åƒå•
        - Moonshot ç­‰
        """
        config = get_config()
        
        # æª¢æŸ¥ OpenAI API Key æ˜¯å¦æœ‰æ•ˆï¼ˆéæ¿¾ä½”ä½ç¬¦ï¼‰
        openai_key_valid = (
            config.openai_api_key and 
            not config.openai_api_key.startswith('your_') and 
            len(config.openai_api_key) > 10
        )
        
        if not openai_key_valid:
            logger.debug("OpenAI å…¼å®¹ API æœªé…ç½®æˆ–é…ç½®ç„¡æ•ˆ")
            return
        
        # åˆ†é›¢ import å’Œå®¢æˆ¶ç«¯å‰µå»ºï¼Œä»¥ä¾¿æä¾›æ›´æº–ç¢ºçš„éŒ¯èª¤ä¿¡æ¯
        try:
            from openai import OpenAI
        except ImportError:
            logger.error("æœªå®‰è£ openai åº«ï¼Œè«‹é‹è¡Œ: pip install openai")
            return
        
        try:
            # base_url å¯é¸ï¼Œä¸å¡«å‰‡ä½¿ç”¨ OpenAI å®˜æ–¹é»˜èªåœ°å€
            client_kwargs = {"api_key": config.openai_api_key}
            if config.openai_base_url and config.openai_base_url.startswith('http'):
                client_kwargs["base_url"] = config.openai_base_url
            
            self._openai_client = OpenAI(**client_kwargs)
            self._current_model_name = config.openai_model
            self._use_openai = True
            logger.info(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–æˆåŠŸ (base_url: {config.openai_base_url}, model: {config.openai_model})")
        except ImportError as e:
            # ä¾è³´ç¼ºå¤±ï¼ˆå¦‚ socksioï¼‰
            if 'socksio' in str(e).lower() or 'socks' in str(e).lower():
                logger.error(f"OpenAI å®¢æˆ¶ç«¯éœ€è¦ SOCKS ä»£ç†æ”¯æŒï¼Œè«‹é‹è¡Œ: pip install httpx[socks] æˆ– pip install socksio")
            else:
                logger.error(f"OpenAI ä¾è³´ç¼ºå¤±: {e}")
        except Exception as e:
            error_msg = str(e).lower()
            if 'socks' in error_msg or 'socksio' in error_msg or 'proxy' in error_msg:
                logger.error(f"OpenAI ä»£ç†é…ç½®éŒ¯èª¤: {e}ï¼Œå¦‚ä½¿ç”¨ SOCKS ä»£ç†è«‹é‹è¡Œ: pip install httpx[socks]")
            else:
                logger.error(f"OpenAI å…¼å®¹ API åˆå§‹åŒ–å¤±æ•—: {e}")
    
    def _init_model(self) -> None:
        """
        åˆå§‹åŒ– Gemini æ¨¡å‹
        
        é…ç½®ï¼š
        - ä½¿ç”¨ gemini-3-flash-preview æˆ– gemini-2.5-flash æ¨¡å‹
        - ä¸å•Ÿç”¨ Google Searchï¼ˆä½¿ç”¨å¤–éƒ¨ Tavily/SerpAPI æœç´¢ï¼‰
        """
        try:
            import google.generativeai as genai
            
            # é…ç½® API Key
            genai.configure(api_key=self._api_key)
            
            # å¾é…ç½®ç²å–æ¨¡å‹åç¨±
            config = get_config()
            model_name = config.gemini_model
            fallback_model = config.gemini_model_fallback
            
            # ä¸å†ä½¿ç”¨ Google Search Groundingï¼ˆå·²çŸ¥æœ‰å…¼å®¹æ€§å•é¡Œï¼‰
            # æ”¹ç‚ºä½¿ç”¨å¤–éƒ¨æœç´¢æœå‹™ï¼ˆTavily/SerpAPIï¼‰é å…ˆç²å–æ–°è
            
            # å˜—è©¦åˆå§‹åŒ–ä¸»æ¨¡å‹
            try:
                self._model = genai.GenerativeModel(
                    model_name=model_name,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = model_name
                self._using_fallback = False
                logger.info(f"Gemini æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {model_name})")
            except Exception as model_error:
                # å˜—è©¦å‚™é¸æ¨¡å‹
                logger.warning(f"ä¸»æ¨¡å‹ {model_name} åˆå§‹åŒ–å¤±æ•—: {model_error}ï¼Œå˜—è©¦å‚™é¸æ¨¡å‹ {fallback_model}")
                self._model = genai.GenerativeModel(
                    model_name=fallback_model,
                    system_instruction=self.SYSTEM_PROMPT,
                )
                self._current_model_name = fallback_model
                self._using_fallback = True
                logger.info(f"Gemini å‚™é¸æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ¨¡å‹: {fallback_model})")
            
        except Exception as e:
            logger.error(f"Gemini æ¨¡å‹åˆå§‹åŒ–å¤±æ•—: {e}")
            self._model = None
    
    def _switch_to_fallback_model(self) -> bool:
        """
        åˆ‡æ›åˆ°å‚™é¸æ¨¡å‹
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ‡æ›
        """
        try:
            import google.generativeai as genai
            config = get_config()
            fallback_model = config.gemini_model_fallback
            
            logger.warning(f"[LLM] åˆ‡æ›åˆ°å‚™é¸æ¨¡å‹: {fallback_model}")
            self._model = genai.GenerativeModel(
                model_name=fallback_model,
                system_instruction=self.SYSTEM_PROMPT,
            )
            self._current_model_name = fallback_model
            self._using_fallback = True
            logger.info(f"[LLM] å‚™é¸æ¨¡å‹ {fallback_model} åˆå§‹åŒ–æˆåŠŸ")
            return True
        except Exception as e:
            logger.error(f"[LLM] åˆ‡æ›å‚™é¸æ¨¡å‹å¤±æ•—: {e}")
            return False
    
    def is_available(self) -> bool:
        """æª¢æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self._model is not None or self._openai_client is not None
    
    def _call_openai_api(self, prompt: str, generation_config: dict) -> str:
        """
        èª¿ç”¨ OpenAI å…¼å®¹ API
        
        Args:
            prompt: æç¤ºè©
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            éŸ¿æ‡‰æ–‡æœ¬
        """
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))
                    delay = min(delay, 60)
                    logger.info(f"[OpenAI] ç¬¬ {attempt + 1} æ¬¡é‡è©¦ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._openai_client.chat.completions.create(
                    model=self._current_model_name,
                    messages=[
                        {"role": "system", "content": self.SYSTEM_PROMPT},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=generation_config.get('temperature', 0.7),
                    max_tokens=generation_config.get('max_output_tokens', 8192),
                )
                
                if response and response.choices and response.choices[0].message.content:
                    return response.choices[0].message.content
                else:
                    raise ValueError("OpenAI API è¿”å›ç©ºéŸ¿æ‡‰")
                    
            except Exception as e:
                error_str = str(e)
                is_rate_limit = '429' in error_str or 'rate' in error_str.lower() or 'quota' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[OpenAI] API é™æµï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å˜—è©¦: {error_str[:100]}")
                else:
                    logger.warning(f"[OpenAI] API èª¿ç”¨å¤±æ•—ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å˜—è©¦: {error_str[:100]}")
                
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("OpenAI API èª¿ç”¨å¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
    
    def _call_api_with_retry(self, prompt: str, generation_config: dict) -> str:
        """
        èª¿ç”¨ AI APIï¼Œå¸¶æœ‰é‡è©¦å’Œæ¨¡å‹åˆ‡æ›æ©Ÿåˆ¶
        
        å„ªå…ˆç´šï¼šGemini > Gemini å‚™é¸æ¨¡å‹ > OpenAI å…¼å®¹ API
        
        è™•ç† 429 é™æµéŒ¯èª¤ï¼š
        1. å…ˆæŒ‡æ•¸é€€é¿é‡è©¦
        2. å¤šæ¬¡å¤±æ•—å¾Œåˆ‡æ›åˆ°å‚™é¸æ¨¡å‹
        3. Gemini å®Œå…¨å¤±æ•—å¾Œå˜—è©¦ OpenAI
        
        Args:
            prompt: æç¤ºè©
            generation_config: ç”Ÿæˆé…ç½®
            
        Returns:
            éŸ¿æ‡‰æ–‡æœ¬
        """
        # å¦‚æœå·²ç¶“åœ¨ä½¿ç”¨ OpenAI æ¨¡å¼ï¼Œç›´æ¥èª¿ç”¨ OpenAI
        if self._use_openai:
            return self._call_openai_api(prompt, generation_config)
        
        config = get_config()
        max_retries = config.gemini_max_retries
        base_delay = config.gemini_retry_delay
        
        last_error = None
        tried_fallback = getattr(self, '_using_fallback', False)
        
        for attempt in range(max_retries):
            try:
                # è«‹æ±‚å‰å¢åŠ å»¶æ™‚ï¼ˆé˜²æ­¢è«‹æ±‚éå¿«è§¸ç™¼é™æµï¼‰
                if attempt > 0:
                    delay = base_delay * (2 ** (attempt - 1))  # æŒ‡æ•¸é€€é¿: 5, 10, 20, 40...
                    delay = min(delay, 60)  # æœ€å¤§60ç§’
                    logger.info(f"[Gemini] ç¬¬ {attempt + 1} æ¬¡é‡è©¦ï¼Œç­‰å¾… {delay:.1f} ç§’...")
                    time.sleep(delay)
                
                response = self._model.generate_content(
                    prompt,
                    generation_config=generation_config,
                    request_options={"timeout": 120}
                )
                
                if response and response.text:
                    return response.text
                else:
                    raise ValueError("Gemini è¿”å›ç©ºéŸ¿æ‡‰")
                    
            except Exception as e:
                last_error = e
                error_str = str(e)
                
                # æª¢æŸ¥æ˜¯å¦æ˜¯ 429 é™æµéŒ¯èª¤
                is_rate_limit = '429' in error_str or 'quota' in error_str.lower() or 'rate' in error_str.lower()
                
                if is_rate_limit:
                    logger.warning(f"[Gemini] API é™æµ (429)ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å˜—è©¦: {error_str[:100]}")
                    
                    # å¦‚æœå·²ç¶“é‡è©¦äº†ä¸€åŠæ¬¡æ•¸ä¸”é‚„æ²’åˆ‡æ›éå‚™é¸æ¨¡å‹ï¼Œå˜—è©¦åˆ‡æ›
                    if attempt >= max_retries // 2 and not tried_fallback:
                        if self._switch_to_fallback_model():
                            tried_fallback = True
                            logger.info("[Gemini] å·²åˆ‡æ›åˆ°å‚™é¸æ¨¡å‹ï¼Œç¹¼çºŒé‡è©¦")
                        else:
                            logger.warning("[Gemini] åˆ‡æ›å‚™é¸æ¨¡å‹å¤±æ•—ï¼Œç¹¼çºŒä½¿ç”¨ç•¶å‰æ¨¡å‹é‡è©¦")
                else:
                    # éé™æµéŒ¯èª¤ï¼Œè¨˜éŒ„ä¸¦ç¹¼çºŒé‡è©¦
                    logger.warning(f"[Gemini] API èª¿ç”¨å¤±æ•—ï¼Œç¬¬ {attempt + 1}/{max_retries} æ¬¡å˜—è©¦: {error_str[:100]}")
        
        # Gemini æ‰€æœ‰é‡è©¦éƒ½å¤±æ•—ï¼Œå˜—è©¦ OpenAI å…¼å®¹ API
        if self._openai_client:
            logger.warning("[Gemini] æ‰€æœ‰é‡è©¦å¤±æ•—ï¼Œåˆ‡æ›åˆ° OpenAI å…¼å®¹ API")
            try:
                return self._call_openai_api(prompt, generation_config)
            except Exception as openai_error:
                logger.error(f"[OpenAI] å‚™é¸ API ä¹Ÿå¤±æ•—: {openai_error}")
                raise last_error or openai_error
        elif config.openai_api_key and config.openai_base_url:
            # å˜—è©¦æ‡¶åŠ è¼‰åˆå§‹åŒ– OpenAI
            logger.warning("[Gemini] æ‰€æœ‰é‡è©¦å¤±æ•—ï¼Œå˜—è©¦åˆå§‹åŒ– OpenAI å…¼å®¹ API")
            self._init_openai_fallback()
            if self._openai_client:
                try:
                    return self._call_openai_api(prompt, generation_config)
                except Exception as openai_error:
                    logger.error(f"[OpenAI] å‚™é¸ API ä¹Ÿå¤±æ•—: {openai_error}")
                    raise last_error or openai_error
        
        # æ‰€æœ‰æ–¹å¼éƒ½å¤±æ•—
        raise last_error or Exception("æ‰€æœ‰ AI API èª¿ç”¨å¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸")
    
    def analyze(
        self, 
        context: Dict[str, Any],
        news_context: Optional[str] = None
    ) -> AnalysisResult:
        """
        åˆ†æå–®éš»è‚¡ç¥¨
        
        æµç¨‹ï¼š
        1. æ ¼å¼åŒ–è¼¸å…¥æ•¸æ“šï¼ˆæŠ€è¡“é¢ + æ–°èï¼‰
        2. èª¿ç”¨ Gemini APIï¼ˆå¸¶é‡è©¦å’Œæ¨¡å‹åˆ‡æ›ï¼‰
        3. è§£æ JSON éŸ¿æ‡‰
        4. è¿”å›çµæ§‹åŒ–çµæœ
        
        Args:
            context: å¾ storage.get_analysis_context() ç²å–çš„ä¸Šä¸‹æ–‡æ•¸æ“š
            news_context: é å…ˆæœç´¢çš„æ–°èå…§å®¹ï¼ˆå¯é¸ï¼‰
            
        Returns:
            AnalysisResult å°è±¡
        """
        code = context.get('code', 'Unknown')
        config = get_config()
        
        # è«‹æ±‚å‰å¢åŠ å»¶æ™‚ï¼ˆé˜²æ­¢é€£çºŒè«‹æ±‚è§¸ç™¼é™æµï¼‰
        request_delay = config.gemini_request_delay
        if request_delay > 0:
            logger.debug(f"[LLM] è«‹æ±‚å‰ç­‰å¾… {request_delay:.1f} ç§’...")
            time.sleep(request_delay)
        
        # å„ªå…ˆå¾ä¸Šä¸‹æ–‡ç²å–è‚¡ç¥¨åç¨±ï¼ˆç”± main.py å‚³å…¥ï¼‰
        name = context.get('stock_name')
        if not name or name.startswith('è‚¡ç¥¨'):
            # å‚™é¸ï¼šå¾ realtime ä¸­ç²å–
            if 'realtime' in context and context['realtime'].get('name'):
                name = context['realtime']['name']
            else:
                # æœ€å¾Œå¾æ˜ å°„è¡¨ç²å–
                name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
        
        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é»˜èªçµæœ
        if not self.is_available():
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡ç›ª',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary='AI åˆ†æåŠŸèƒ½æœªå•Ÿç”¨ï¼ˆæœªé…ç½® API Keyï¼‰',
                risk_warning='è«‹é…ç½® Gemini API Key å¾Œé‡è©¦',
                success=False,
                error_message='Gemini API Key æœªé…ç½®',
            )
        
        try:
            # æ ¼å¼åŒ–è¼¸å…¥ï¼ˆåŒ…å«æŠ€è¡“é¢æ•¸æ“šå’Œæ–°èï¼‰
            prompt = self._format_prompt(context, name, news_context)
            
            # ç²å–æ¨¡å‹åç¨±
            model_name = getattr(self, '_current_model_name', None)
            if not model_name:
                model_name = getattr(self._model, '_model_name', 'unknown')
                if hasattr(self._model, 'model_name'):
                    model_name = self._model.model_name
            
            logger.info(f"========== AI åˆ†æ {name}({code}) ==========")
            logger.info(f"[LLMé…ç½®] æ¨¡å‹: {model_name}")
            logger.info(f"[LLMé…ç½®] Prompt é•·åº¦: {len(prompt)} å­—ç¬¦")
            logger.info(f"[LLMé…ç½®] æ˜¯å¦åŒ…å«æ–°è: {'æ˜¯' if news_context else 'å¦'}")
            
            # è¨˜éŒ„å®Œæ•´ prompt åˆ°æ—¥èªŒï¼ˆINFOç´šåˆ¥è¨˜éŒ„æ‘˜è¦ï¼ŒDEBUGè¨˜éŒ„å®Œæ•´ï¼‰
            prompt_preview = prompt[:500] + "..." if len(prompt) > 500 else prompt
            logger.info(f"[LLM Prompt é è¦½]\n{prompt_preview}")
            logger.debug(f"=== å®Œæ•´ Prompt ({len(prompt)}å­—ç¬¦) ===\n{prompt}\n=== End Prompt ===")
            
            # è¨­ç½®ç”Ÿæˆé…ç½®
            generation_config = {
                "temperature": 0.7,
                "max_output_tokens": 8192,
            }
            
            logger.info(f"[LLMèª¿ç”¨] é–‹å§‹èª¿ç”¨ Gemini API (temperature={generation_config['temperature']}, max_tokens={generation_config['max_output_tokens']})...")
            
            # ä½¿ç”¨å¸¶é‡è©¦çš„ API èª¿ç”¨
            start_time = time.time()
            response_text = self._call_api_with_retry(prompt, generation_config)
            elapsed = time.time() - start_time
            
            # è¨˜éŒ„éŸ¿æ‡‰ä¿¡æ¯
            logger.info(f"[LLMè¿”å›] Gemini API éŸ¿æ‡‰æˆåŠŸ, è€—æ™‚ {elapsed:.2f}s, éŸ¿æ‡‰é•·åº¦ {len(response_text)} å­—ç¬¦")
            
            # è¨˜éŒ„éŸ¿æ‡‰é è¦½ï¼ˆINFOç´šåˆ¥ï¼‰å’Œå®Œæ•´éŸ¿æ‡‰ï¼ˆDEBUGç´šåˆ¥ï¼‰
            response_preview = response_text[:300] + "..." if len(response_text) > 300 else response_text
            logger.info(f"[LLMè¿”å› é è¦½]\n{response_preview}")
            logger.debug(f"=== Gemini å®Œæ•´éŸ¿æ‡‰ ({len(response_text)}å­—ç¬¦) ===\n{response_text}\n=== End Response ===")
            
            # è§£æéŸ¿æ‡‰
            result = self._parse_response(response_text, code, name)
            result.raw_response = response_text
            result.search_performed = bool(news_context)
            
            logger.info(f"[LLMè§£æ] {name}({code}) åˆ†æå®Œæˆ: {result.trend_prediction}, è©•åˆ† {result.sentiment_score}")
            
            return result
            
        except Exception as e:
            logger.error(f"AI åˆ†æ {name}({code}) å¤±æ•—: {e}")
            return AnalysisResult(
                code=code,
                name=name,
                sentiment_score=50,
                trend_prediction='éœ‡ç›ª',
                operation_advice='æŒæœ‰',
                confidence_level='ä½',
                analysis_summary=f'åˆ†æéç¨‹å‡ºéŒ¯: {str(e)[:100]}',
                risk_warning='åˆ†æå¤±æ•—ï¼Œè«‹ç¨å¾Œé‡è©¦æˆ–æ‰‹å‹•åˆ†æ',
                success=False,
                error_message=str(e),
            )
    
    def _format_prompt(
        self, 
        context: Dict[str, Any], 
        name: str,
        news_context: Optional[str] = None
    ) -> str:
        """
        æ ¼å¼åŒ–åˆ†ææç¤ºè©ï¼ˆæ±ºç­–å„€è¡¨ç›¤ v2.0ï¼‰
        
        åŒ…å«ï¼šæŠ€è¡“æŒ‡æ¨™ã€å¯¦æ™‚è¡Œæƒ…ï¼ˆé‡æ¯”/æ›æ‰‹ç‡ï¼‰ã€ç±Œç¢¼åˆ†ä½ˆã€è¶¨å‹¢åˆ†æã€æ–°è
        
        Args:
            context: æŠ€è¡“é¢æ•¸æ“šä¸Šä¸‹æ–‡ï¼ˆåŒ…å«å¢å¼·æ•¸æ“šï¼‰
            name: è‚¡ç¥¨åç¨±ï¼ˆé»˜èªå€¼ï¼Œå¯èƒ½è¢«ä¸Šä¸‹æ–‡è¦†è“‹ï¼‰
            news_context: é å…ˆæœç´¢çš„æ–°èå…§å®¹
        """
        code = context.get('code', 'Unknown')
        
        # å„ªå…ˆä½¿ç”¨ä¸Šä¸‹æ–‡ä¸­çš„è‚¡ç¥¨åç¨±ï¼ˆå¾ realtime_quote ç²å–ï¼‰
        stock_name = context.get('stock_name', name)
        if not stock_name or stock_name == f'è‚¡ç¥¨{code}':
            stock_name = STOCK_NAME_MAP.get(code, f'è‚¡ç¥¨{code}')
            
        today = context.get('today', {})
        
        # ========== æ§‹å»ºæ±ºç­–å„€è¡¨ç›¤æ ¼å¼çš„è¼¸å…¥ ==========
        prompt = f"""# æ±ºç­–å„€è¡¨ç›¤åˆ†æè«‹æ±‚

## ğŸ“Š è‚¡ç¥¨åŸºç¤ä¿¡æ¯
| é …ç›® | æ•¸æ“š |
|------|------|
| è‚¡ç¥¨ä»£ç¢¼ | **{code}** |
| è‚¡ç¥¨åç¨± | **{stock_name}** |
| åˆ†ææ—¥æœŸ | {context.get('date', 'æœªçŸ¥')} |

---

## ğŸ“ˆ æŠ€è¡“é¢æ•¸æ“š

### ä»Šæ—¥è¡Œæƒ…
| æŒ‡æ¨™ | æ•¸å€¼ |
|------|------|
| æ”¶ç›¤åƒ¹ | {today.get('close', 'N/A')} å…ƒ |
| é–‹ç›¤åƒ¹ | {today.get('open', 'N/A')} å…ƒ |
| æœ€é«˜åƒ¹ | {today.get('high', 'N/A')} å…ƒ |
| æœ€ä½åƒ¹ | {today.get('low', 'N/A')} å…ƒ |
| æ¼²è·Œå¹… | {today.get('pct_chg', 'N/A')}% |
| æˆäº¤é‡ | {self._format_volume(today.get('volume'))} |
| æˆäº¤é¡ | {self._format_amount(today.get('amount'))} |

### å‡ç·šç³»çµ±ï¼ˆé—œéµåˆ¤æ–·æŒ‡æ¨™ï¼‰
| å‡ç·š | æ•¸å€¼ | èªªæ˜ |
|------|------|------|
| MA5 | {today.get('ma5', 'N/A')} | çŸ­æœŸè¶¨å‹¢ç·š |
| MA10 | {today.get('ma10', 'N/A')} | ä¸­çŸ­æœŸè¶¨å‹¢ç·š |
| MA20 | {today.get('ma20', 'N/A')} | ä¸­æœŸè¶¨å‹¢ç·š |
| å‡ç·šå½¢æ…‹ | {context.get('ma_status', 'æœªçŸ¥')} | å¤šé ­/ç©ºé ­/çºç¹ |
"""
        
        # æ·»åŠ å¯¦æ™‚è¡Œæƒ…æ•¸æ“šï¼ˆé‡æ¯”ã€æ›æ‰‹ç‡ç­‰ï¼‰
        if 'realtime' in context:
            rt = context['realtime']
            prompt += f"""
### å¯¦æ™‚è¡Œæƒ…å¢å¼·æ•¸æ“š
| æŒ‡æ¨™ | æ•¸å€¼ | è§£è®€ |
|------|------|------|
| ç•¶å‰åƒ¹æ ¼ | {rt.get('price', 'N/A')} å…ƒ | |
| **é‡æ¯”** | **{rt.get('volume_ratio', 'N/A')}** | {rt.get('volume_ratio_desc', '')} |
| **æ›æ‰‹ç‡** | **{rt.get('turnover_rate', 'N/A')}%** | |
| å¸‚ç›ˆç‡(å‹•æ…‹) | {rt.get('pe_ratio', 'N/A')} | |
| å¸‚æ·¨ç‡ | {rt.get('pb_ratio', 'N/A')} | |
| ç¸½å¸‚å€¼ | {self._format_amount(rt.get('total_mv'))} | |
| æµé€šå¸‚å€¼ | {self._format_amount(rt.get('circ_mv'))} | |
| 60æ—¥æ¼²è·Œå¹… | {rt.get('change_60d', 'N/A')}% | ä¸­æœŸè¡¨ç¾ |
"""
        
        # æ·»åŠ ç±Œç¢¼åˆ†ä½ˆæ•¸æ“š
        if 'chip' in context:
            chip = context['chip']
            profit_ratio = chip.get('profit_ratio', 0)
            prompt += f"""
### ç±Œç¢¼åˆ†ä½ˆæ•¸æ“šï¼ˆæ•ˆç‡æŒ‡æ¨™ï¼‰
| æŒ‡æ¨™ | æ•¸å€¼ | å¥åº·æ¨™æº– |
|------|------|----------|
| **ç²åˆ©æ¯”ä¾‹** | **{profit_ratio:.1%}** | 70-90%æ™‚è­¦æƒ• |
| å¹³å‡æˆæœ¬ | {chip.get('avg_cost', 'N/A')} å…ƒ | ç¾åƒ¹æ‡‰é«˜æ–¼5-15% |
| 90%ç±Œç¢¼é›†ä¸­åº¦ | {chip.get('concentration_90', 0):.2%} | <15%ç‚ºé›†ä¸­ |
| 70%ç±Œç¢¼é›†ä¸­åº¦ | {chip.get('concentration_70', 0):.2%} | |
| ç±Œç¢¼ç‹€æ…‹ | {chip.get('chip_status', 'æœªçŸ¥')} | |
"""
        
        # æ·»åŠ è¶¨å‹¢åˆ†æçµæœï¼ˆåŸºæ–¼äº¤æ˜“ç†å¿µçš„é åˆ¤ï¼‰
        if 'trend_analysis' in context:
            trend = context['trend_analysis']
            bias_warning = "ğŸš¨ è¶…é5%ï¼Œåš´ç¦è¿½é«˜ï¼" if trend.get('bias_ma5', 0) > 5 else "âœ… å®‰å…¨ç¯„åœ"
            prompt += f"""
### è¶¨å‹¢åˆ†æé åˆ¤ï¼ˆåŸºæ–¼äº¤æ˜“ç†å¿µï¼‰
| æŒ‡æ¨™ | æ•¸å€¼ | åˆ¤å®š |
|------|------|------|
| è¶¨å‹¢ç‹€æ…‹ | {trend.get('trend_status', 'æœªçŸ¥')} | |
| å‡ç·šæ’åˆ— | {trend.get('ma_alignment', 'æœªçŸ¥')} | MA5>MA10>MA20ç‚ºå¤šé ­ |
| è¶¨å‹¢å¼·åº¦ | {trend.get('trend_strength', 0)}/100 | |
| **ä¹–é›¢ç‡(MA5)** | **{trend.get('bias_ma5', 0):+.2f}%** | {bias_warning} |
| ä¹–é›¢ç‡(MA10) | {trend.get('bias_ma10', 0):+.2f}% | |
| é‡èƒ½ç‹€æ…‹ | {trend.get('volume_status', 'æœªçŸ¥')} | {trend.get('volume_trend', '')} |
| ç³»çµ±ä¿¡è™Ÿ | {trend.get('buy_signal', 'æœªçŸ¥')} | |
| ç³»çµ±è©•åˆ† | {trend.get('signal_score', 0)}/100 | |

#### ç³»çµ±åˆ†æç†ç”±
**è²·å…¥ç†ç”±**ï¼š
{chr(10).join('- ' + r for r in trend.get('signal_reasons', ['ç„¡'])) if trend.get('signal_reasons') else '- ç„¡'}

**é¢¨éšªå› ç´ **ï¼š
{chr(10).join('- ' + r for r in trend.get('risk_factors', ['ç„¡'])) if trend.get('risk_factors') else '- ç„¡'}
"""
        
        # æ·»åŠ æ˜¨æ—¥å°æ¯”æ•¸æ“š
        if 'yesterday' in context:
            volume_change = context.get('volume_change_ratio', 'N/A')
            prompt += f"""
### é‡åƒ¹è®ŠåŒ–
- æˆäº¤é‡è¼ƒæ˜¨æ—¥è®ŠåŒ–ï¼š{volume_change}å€
- åƒ¹æ ¼è¼ƒæ˜¨æ—¥è®ŠåŒ–ï¼š{context.get('price_change_ratio', 'N/A')}%
"""
        
        # æ·»åŠ æ–°èæœç´¢çµæœï¼ˆé‡é»å€åŸŸï¼‰
        prompt += """
---

## ğŸ“° è¼¿æƒ…æƒ…å ±
"""
        if news_context:
            prompt += f"""
ä»¥ä¸‹æ˜¯ **{stock_name}({code})** è¿‘7æ—¥çš„æ–°èæœç´¢çµæœï¼Œè«‹é‡é»æå–ï¼š
1. ğŸš¨ **é¢¨éšªè­¦å ±**ï¼šæ¸›æŒã€è™•ç½°ã€åˆ©ç©º
2. ğŸ¯ **åˆ©å¥½å‚¬åŒ–**ï¼šæ¥­ç¸¾ã€åˆåŒã€æ”¿ç­–
3. ğŸ“Š **æ¥­ç¸¾é æœŸ**ï¼šå¹´å ±é å‘Šã€æ¥­ç¸¾å¿«å ±

```
{news_context}
```
"""
        else:
            prompt += """
æœªæœç´¢åˆ°è©²è‚¡ç¥¨è¿‘æœŸçš„ç›¸é—œæ–°èã€‚è«‹ä¸»è¦ä¾æ“šæŠ€è¡“é¢æ•¸æ“šé€²è¡Œåˆ†æã€‚
"""
        
        # æ˜ç¢ºçš„è¼¸å‡ºè¦æ±‚
        prompt += f"""
---

## âœ… åˆ†æä»»å‹™

è«‹ç‚º **{stock_name}({code})** ç”Ÿæˆã€æ±ºç­–å„€è¡¨ç›¤ã€‘ï¼Œåš´æ ¼æŒ‰ç…§ JSON æ ¼å¼è¼¸å‡ºã€‚

### é‡é»é—œæ³¨ï¼ˆå¿…é ˆæ˜ç¢ºå›ç­”ï¼‰ï¼š
1. â“ æ˜¯å¦æ»¿è¶³ MA5>MA10>MA20 å¤šé ­æ’åˆ—ï¼Ÿ
2. â“ ç•¶å‰ä¹–é›¢ç‡æ˜¯å¦åœ¨å®‰å…¨ç¯„åœå…§ï¼ˆ<5%ï¼‰ï¼Ÿâ€”â€” è¶…é5%å¿…é ˆæ¨™è¨»"åš´ç¦è¿½é«˜"
3. â“ é‡èƒ½æ˜¯å¦é…åˆï¼ˆç¸®é‡å›èª¿/æ”¾é‡çªç ´ï¼‰ï¼Ÿ
4. â“ ç±Œç¢¼çµæ§‹æ˜¯å¦å¥åº·ï¼Ÿ
5. â“ æ¶ˆæ¯é¢æœ‰ç„¡é‡å¤§åˆ©ç©ºï¼Ÿï¼ˆæ¸›æŒã€è™•ç½°ã€æ¥­ç¸¾è®Šè‡‰ç­‰ï¼‰

### æ±ºç­–å„€è¡¨ç›¤è¦æ±‚ï¼š
- **æ ¸å¿ƒçµè«–**ï¼šä¸€å¥è©±èªªæ¸…è©²è²·/è©²è³£/è©²ç­‰
- **æŒå€‰åˆ†é¡å»ºè­°**ï¼šç©ºå€‰è€…æ€éº¼åš vs æŒå€‰è€…æ€éº¼åš
- **å…·é«”ç‹™æ“Šé»ä½**ï¼šè²·å…¥åƒ¹ã€æ­¢æåƒ¹ã€ç›®æ¨™åƒ¹ï¼ˆç²¾ç¢ºåˆ°åˆ†ï¼‰
- **æª¢æŸ¥æ¸…å–®**ï¼šæ¯é …ç”¨ âœ…/âš ï¸/âŒ æ¨™è¨˜

è«‹è¼¸å‡ºå®Œæ•´çš„ JSON æ ¼å¼æ±ºç­–å„€è¡¨ç›¤ã€‚"""
        
        return prompt
    
    def _format_volume(self, volume: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é‡é¡¯ç¤º"""
        if volume is None:
            return 'N/A'
        if volume >= 1e8:
            return f"{volume / 1e8:.2f} å„„è‚¡"
        elif volume >= 1e4:
            return f"{volume / 1e4:.2f} è¬è‚¡"
        else:
            return f"{volume:.0f} è‚¡"
    
    def _format_amount(self, amount: Optional[float]) -> str:
        """æ ¼å¼åŒ–æˆäº¤é¡é¡¯ç¤º"""
        if amount is None:
            return 'N/A'
        if amount >= 1e8:
            return f"{amount / 1e8:.2f} å„„å…ƒ"
        elif amount >= 1e4:
            return f"{amount / 1e4:.2f} è¬å…ƒ"
        else:
            return f"{amount:.0f} å…ƒ"
    
    def _parse_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """
        è§£æ Gemini éŸ¿æ‡‰ï¼ˆæ±ºç­–å„€è¡¨ç›¤ç‰ˆï¼‰
        
        å˜—è©¦å¾éŸ¿æ‡‰ä¸­æå– JSON æ ¼å¼çš„åˆ†æçµæœï¼ŒåŒ…å« dashboard å­—æ®µ
        å¦‚æœè§£æå¤±æ•—ï¼Œå˜—è©¦æ™ºèƒ½æå–æˆ–è¿”å›é»˜èªçµæœ
        """
        try:
            # æ¸…ç†éŸ¿æ‡‰æ–‡æœ¬ï¼šç§»é™¤ markdown ä»£ç¢¼å¡Šæ¨™è¨˜
            cleaned_text = response_text
            if '```json' in cleaned_text:
                cleaned_text = cleaned_text.replace('```json', '').replace('```', '')
            elif '```' in cleaned_text:
                cleaned_text = cleaned_text.replace('```', '')
            
            # å˜—è©¦æ‰¾åˆ° JSON å…§å®¹
            json_start = cleaned_text.find('{')
            json_end = cleaned_text.rfind('}') + 1
            
            if json_start >= 0 and json_end > json_start:
                json_str = cleaned_text[json_start:json_end]
                
                # å˜—è©¦ä¿®å¾©å¸¸è¦‹çš„ JSON å•é¡Œ
                json_str = self._fix_json_string(json_str)
                
                data = json.loads(json_str)
                
                # æå– dashboard æ•¸æ“š
                dashboard = data.get('dashboard', None)
                
                # è§£ææ‰€æœ‰å­—æ®µï¼Œä½¿ç”¨é»˜èªå€¼é˜²æ­¢ç¼ºå¤±
                return AnalysisResult(
                    code=code,
                    name=name,
                    # æ ¸å¿ƒæŒ‡æ¨™
                    sentiment_score=int(data.get('sentiment_score', 50)),
                    trend_prediction=data.get('trend_prediction', 'éœ‡ç›ª'),
                    operation_advice=data.get('operation_advice', 'æŒæœ‰'),
                    confidence_level=data.get('confidence_level', 'ä¸­'),
                    # æ±ºç­–å„€è¡¨ç›¤
                    dashboard=dashboard,
                    # èµ°å‹¢åˆ†æ
                    trend_analysis=data.get('trend_analysis', ''),
                    short_term_outlook=data.get('short_term_outlook', ''),
                    medium_term_outlook=data.get('medium_term_outlook', ''),
                    # æŠ€è¡“é¢
                    technical_analysis=data.get('technical_analysis', ''),
                    ma_analysis=data.get('ma_analysis', ''),
                    volume_analysis=data.get('volume_analysis', ''),
                    pattern_analysis=data.get('pattern_analysis', ''),
                    # åŸºæœ¬é¢
                    fundamental_analysis=data.get('fundamental_analysis', ''),
                    sector_position=data.get('sector_position', ''),
                    company_highlights=data.get('company_highlights', ''),
                    # æƒ…ç·’é¢/æ¶ˆæ¯é¢
                    news_summary=data.get('news_summary', ''),
                    market_sentiment=data.get('market_sentiment', ''),
                    hot_topics=data.get('hot_topics', ''),
                    # ç¶œåˆ
                    analysis_summary=data.get('analysis_summary', 'åˆ†æå®Œæˆ'),
                    key_points=data.get('key_points', ''),
                    risk_warning=data.get('risk_warning', ''),
                    buy_reason=data.get('buy_reason', ''),
                    # å…ƒæ•¸æ“š
                    search_performed=data.get('search_performed', False),
                    data_sources=data.get('data_sources', 'æŠ€è¡“é¢æ•¸æ“š'),
                    success=True,
                )
            else:
                # æ²’æœ‰æ‰¾åˆ° JSONï¼Œå˜—è©¦å¾ç´”æ–‡æœ¬ä¸­æå–ä¿¡æ¯
                logger.warning(f"ç„¡æ³•å¾éŸ¿æ‡‰ä¸­æå– JSONï¼Œä½¿ç”¨åŸå§‹æ–‡æœ¬åˆ†æ")
                return self._parse_text_response(response_text, code, name)
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON è§£æå¤±æ•—: {e}ï¼Œå˜—è©¦å¾æ–‡æœ¬æå–")
            return self._parse_text_response(response_text, code, name)
    
    def _fix_json_string(self, json_str: str) -> str:
        """ä¿®å¾©å¸¸è¦‹çš„ JSON æ ¼å¼å•é¡Œ"""
        import re
        
        # ç§»é™¤è¨»é‡‹
        json_str = re.sub(r'//.*?\n', '\n', json_str)
        json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
        
        # ä¿®å¾©å°¾éš¨é€—è™Ÿ
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¢ºä¿å¸ƒçˆ¾å€¼æ˜¯å°å¯«
        json_str = json_str.replace('True', 'true').replace('False', 'false')
        
        return json_str
    
    def _parse_text_response(
        self, 
        response_text: str, 
        code: str, 
        name: str
    ) -> AnalysisResult:
        """å¾ç´”æ–‡æœ¬éŸ¿æ‡‰ä¸­å„˜å¯èƒ½æå–åˆ†æä¿¡æ¯"""
        # å˜—è©¦è­˜åˆ¥é—œéµè©ä¾†åˆ¤æ–·æƒ…ç·’
        sentiment_score = 50
        trend = 'éœ‡ç›ª'
        advice = 'æŒæœ‰'
        
        text_lower = response_text.lower()
        
        # ç°¡å–®çš„æƒ…ç·’è­˜åˆ¥
        positive_keywords = ['çœ‹å¤š', 'è²·å…¥', 'ä¸Šæ¼²', 'çªç ´', 'å¼·å‹¢', 'åˆ©å¥½', 'åŠ å€‰', 'bullish', 'buy']
        negative_keywords = ['çœ‹ç©º', 'è³£å‡º', 'ä¸‹è·Œ', 'è·Œç ´', 'å¼±å‹¢', 'åˆ©ç©º', 'æ¸›å€‰', 'bearish', 'sell']
        
        positive_count = sum(1 for kw in positive_keywords if kw in text_lower)
        negative_count = sum(1 for kw in negative_keywords if kw in text_lower)
        
        if positive_count > negative_count + 1:
            sentiment_score = 65
            trend = 'çœ‹å¤š'
            advice = 'è²·å…¥'
        elif negative_count > positive_count + 1:
            sentiment_score = 35
            trend = 'çœ‹ç©º'
            advice = 'è³£å‡º'
        
        # æˆªå–å‰500å­—ç¬¦ä½œç‚ºæ‘˜è¦
        summary = response_text[:500] if response_text else 'ç„¡åˆ†æçµæœ'
        
        return AnalysisResult(
            code=code,
            name=name,
            sentiment_score=sentiment_score,
            trend_prediction=trend,
            operation_advice=advice,
            confidence_level='ä½',
            analysis_summary=summary,
            key_points='JSONè§£æå¤±æ•—ï¼Œåƒ…ä¾›åƒè€ƒ',
            risk_warning='åˆ†æçµæœå¯èƒ½ä¸æº–ç¢ºï¼Œå»ºè­°çµåˆå…¶ä»–ä¿¡æ¯åˆ¤æ–·',
            raw_response=response_text,
            success=True,
        )
    
    def batch_analyze(
        self, 
        contexts: List[Dict[str, Any]],
        delay_between: float = 2.0
    ) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æå¤šéš»è‚¡ç¥¨
        
        æ³¨æ„ï¼šç‚ºé¿å… API é€Ÿç‡é™åˆ¶ï¼Œæ¯æ¬¡åˆ†æä¹‹é–“æœƒæœ‰å»¶é²
        
        Args:
            contexts: ä¸Šä¸‹æ–‡æ•¸æ“šåˆ—è¡¨
            delay_between: æ¯æ¬¡åˆ†æä¹‹é–“çš„å»¶é²ï¼ˆç§’ï¼‰
            
        Returns:
            AnalysisResult åˆ—è¡¨
        """
        results = []
        
        for i, context in enumerate(contexts):
            if i > 0:
                logger.debug(f"ç­‰å¾… {delay_between} ç§’å¾Œç¹¼çºŒ...")
                time.sleep(delay_between)
            
            result = self.analyze(context)
            results.append(result)
        
        return results


# ä¾¿æ·å‡½æ•¸
def get_analyzer() -> GeminiAnalyzer:
    """ç²å– Gemini åˆ†æå™¨å¯¦ä¾‹"""
    return GeminiAnalyzer()


if __name__ == "__main__":
    # æ¸¬è©¦ä»£ç¢¼
    logging.basicConfig(level=logging.DEBUG)
    
    # æ¨¡æ“¬ä¸Šä¸‹æ–‡æ•¸æ“š
    test_context = {
        'code': '600519',
        'date': '2026-01-09',
        'today': {
            'open': 1800.0,
            'high': 1850.0,
            'low': 1780.0,
            'close': 1820.0,
            'volume': 10000000,
            'amount': 18200000000,
            'pct_chg': 1.5,
            'ma5': 1810.0,
            'ma10': 1800.0,
            'ma20': 1790.0,
            'volume_ratio': 1.2,
        },
        'ma_status': 'å¤šé ­æ’åˆ— ğŸ“ˆ',
        'volume_change_ratio': 1.3,
        'price_change_ratio': 1.5,
    }
    
    analyzer = GeminiAnalyzer()
    
    if analyzer.is_available():
        print("=== AI åˆ†ææ¸¬è©¦ ===")
        result = analyzer.analyze(test_context)
        print(f"åˆ†æçµæœ: {result.to_dict()}")
    else:
        print("Gemini API æœªé…ç½®ï¼Œè·³éæ¸¬è©¦")
