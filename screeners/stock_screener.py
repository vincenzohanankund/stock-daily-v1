# -*- coding: utf-8 -*-
"""
===================================
è‚¡ç¥¨é€‰è‚¡æ¨¡å— - ç»¼åˆç­–ç•¥é€‰è‚¡
===================================

èŒè´£ï¼š
1. å…¨å¸‚åœºæ•°æ®è·å–ï¼ˆä½¿ç”¨ akshareï¼‰
2. æŠ€æœ¯æŒ‡æ ‡ç­›é€‰ï¼ˆç¬¬ä¸€å±‚ï¼‰ï¼šå¿«é€Ÿè¿‡æ»¤ 5000+ â†’ 20-30
3. AIæ™ºèƒ½ç­›é€‰ï¼ˆç¬¬äºŒå±‚ï¼‰ï¼šæ·±åº¦ç²¾é€‰ 20-30 â†’ 5-10
4. é€‰è‚¡ç»“æœå­˜å‚¨å’Œé€šçŸ¥

æ ¸å¿ƒæµç¨‹ï¼š
    å…¨å¸‚åœºæ•°æ®è·å– â†’ æŠ€æœ¯æŒ‡æ ‡ç­›é€‰ï¼ˆç¬¬ä¸€å±‚ï¼‰ â†’ AIæ·±åº¦åˆ†æï¼ˆç¬¬äºŒå±‚ï¼‰ â†’ ç»“æœå­˜å‚¨/é€šçŸ¥
        (åˆ†æ‰¹+é™æµ)        (å¿«é€Ÿè¿‡æ»¤5000â†’20)        (æ·±åº¦ç²¾é€‰20â†’5)         (è‡ªåŠ¨åŠ å…¥åˆ†æ)
"""

import json
import logging
import os
import random
import time
from dataclasses import dataclass, field
from datetime import datetime, date
from typing import Optional, List, Dict, Any, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed
from enum import Enum

import pandas as pd
import numpy as np

from config import get_config
from core.storage import get_db, DatabaseManager, ScreeningResultDB, and_, desc
from core.analyzer import GeminiAnalyzer, AnalysisResult, STOCK_NAME_MAP
from core.stock_analyzer import StockTrendAnalyzer, TrendAnalysisResult
from data_provider.akshare_fetcher import AkshareFetcher
from data_provider.data_cache_manager import get_cache_manager
from services.search_service import SearchService

logger = logging.getLogger(__name__)


# ==================== æ•°æ®æ¨¡å‹ ====================

class ScreeningMode(Enum):
    """é€‰è‚¡æ¨¡å¼"""
    TECH_ONLY = "tech_only"       # ä»…æŠ€æœ¯ç­›é€‰
    AI_ONLY = "ai_only"           # ä»…AIç­›é€‰ï¼ˆè·³è¿‡æŠ€æœ¯ç­›é€‰ï¼‰
    FULL = "full"                 # å®Œæ•´æµç¨‹ï¼ˆæŠ€æœ¯+AIï¼‰


@dataclass
class ScreeningCriteria:
    """é€‰è‚¡ç­›é€‰æ¡ä»¶"""
    # æŠ€æœ¯æŒ‡æ ‡æ¡ä»¶
    min_trend_strength: int = 60      # æœ€å°è¶‹åŠ¿å¼ºåº¦ï¼ˆ0-100ï¼‰
    max_bias_ma5: float = 5.0         # æœ€å¤§ä¹–ç¦»ç‡ï¼ˆ%ï¼‰
    min_volume_ratio: float = 0.8     # æœ€å°é‡æ¯”
    max_volume_ratio: float = 3.0     # æœ€å¤§é‡æ¯”
    bullish_alignment: bool = True    # æ˜¯å¦è¦æ±‚å¤šå¤´æ’åˆ—

    # å¸‚åœºæ¡ä»¶
    min_price: float = 5.0            # æœ€ä½ä»·æ ¼ï¼ˆæ’é™¤ä»™è‚¡ï¼‰
    max_price: float = 1000.0         # æœ€é«˜ä»·æ ¼
    min_turnover: float = 0.5         # æœ€å°æ¢æ‰‹ç‡

    # æ¿å—è¿‡æ»¤
    exclude_st: bool = True           # æ’é™¤STè‚¡ç¥¨
    exclude_new_listed_days: int = 60 # æ’é™¤æ–°ä¸Šå¸‚å¤©æ•°

    # AIç­›é€‰é…ç½®
    ai_filter_enabled: bool = True    # æ˜¯å¦å¯ç”¨AIç­›é€‰
    max_candidates: int = 20          # AIç­›é€‰æœ€å¤§å€™é€‰æ•°
    final_selection: int = 5          # æœ€ç»ˆé€‰ä¸­æ•°é‡

    # å¹¶å‘æ§åˆ¶
    batch_size: int = 100             # åˆ†æ‰¹å¤§å°
    request_delay: float = 2.0        # è¯·æ±‚å»¶è¿Ÿï¼ˆç§’ï¼‰


@dataclass
class ScreeningResult:
    """é€‰è‚¡ç»“æœ"""
    code: str                         # è‚¡ç¥¨ä»£ç 
    name: str                         # è‚¡ç¥¨åç§°
    tech_score: float                 # æŠ€æœ¯è¯„åˆ†ï¼ˆ0-100ï¼‰
    tech_reasons: List[str]           # æŠ€æœ¯é¢ç†ç”±
    ai_result: Optional[AnalysisResult] = None  # AIåˆ†æç»“æœ
    screen_time: datetime = None      # é€‰è‚¡æ—¶é—´

    def __post_init__(self):
        if self.screen_time is None:
            self.screen_time = datetime.now()


# ==================== æ ¸å¿ƒé€‰è‚¡å™¨ ====================

class StockScreener:
    """
    è‚¡ç¥¨é€‰è‚¡å™¨ - ä¸»æ§åˆ¶å™¨

    èŒè´£ï¼š
    1. è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨
    2. æ‰§è¡ŒæŠ€æœ¯æŒ‡æ ‡ç­›é€‰ï¼ˆç¬¬ä¸€å±‚ï¼‰
    3. æ‰§è¡ŒAIæ™ºèƒ½ç­›é€‰ï¼ˆç¬¬äºŒå±‚ï¼‰
    4. ä¿å­˜å’Œæ¨é€é€‰è‚¡ç»“æœ
    """

    def __init__(
        self,
        criteria: Optional[ScreeningCriteria] = None,
        max_workers: int = 3,
        db: Optional[DatabaseManager] = None
    ):
        """
        åˆå§‹åŒ–é€‰è‚¡å™¨

        Args:
            criteria: ç­›é€‰æ¡ä»¶ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ï¼‰
            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°
            db: æ•°æ®åº“ç®¡ç†å™¨ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨å…¨å±€å®ä¾‹ï¼‰
        """
        self.config = get_config()
        self.criteria = criteria or self._load_criteria_from_config()
        self.max_workers = max_workers
        self.db = db or get_db()

        # åˆå§‹åŒ–å„æ¨¡å—
        self.fetcher = AkshareFetcher(
            sleep_min=self.config.akshare_sleep_min,
            sleep_max=self.config.akshare_sleep_max
        )
        self.trend_analyzer = StockTrendAnalyzer()
        self.ai_analyzer = GeminiAnalyzer()

        # åˆå§‹åŒ–æœç´¢æœåŠ¡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        self.search_service = None
        if self.config.tavily_api_keys or self.config.serpapi_keys:
            self.search_service = SearchService(
                tavily_keys=self.config.tavily_api_keys,
                serpapi_keys=self.config.serpapi_keys
            )

        logger.info(f"é€‰è‚¡å™¨åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"ç­›é€‰æ¡ä»¶: è¶‹åŠ¿å¼ºåº¦>={self.criteria.min_trend_strength}, "
                   f"ä¹–ç¦»ç‡<={self.criteria.max_bias_ma5}%, "
                   f"é‡æ¯”={self.criteria.min_volume_ratio}-{self.criteria.max_volume_ratio}")
        logger.info(f"ä»·æ ¼åŒºé—´: {self.criteria.min_price}-{self.criteria.max_price}å…ƒ, "
                   f"æ¢æ‰‹ç‡>={self.criteria.min_turnover}%")
        if self.criteria.ai_filter_enabled:
            logger.info(f"AIç­›é€‰: å¯ç”¨, æœ€å¤§å€™é€‰æ•°={self.criteria.max_candidates}, "
                       f"æœ€ç»ˆé€‰ä¸­={self.criteria.final_selection}")
        else:
            logger.info(f"AIç­›é€‰: ç¦ç”¨")

    def _load_criteria_from_config(self) -> ScreeningCriteria:
        """ä»é…ç½®åŠ è½½ç­›é€‰æ¡ä»¶"""
        return ScreeningCriteria(
            min_trend_strength=int(os.getenv('SREENER_MIN_TRENGTH', '60')),
            max_bias_ma5=float(os.getenv('SREENER_MAX_BIAS_MA5', '5.0')),
            min_volume_ratio=float(os.getenv('SREENER_MIN_VOLUME_RATIO', '0.8')),
            max_volume_ratio=float(os.getenv('SREENER_MAX_VOLUME_RATIO', '3.0')),
            bullish_alignment=os.getenv('SREENER_BULLISH_ONLY', 'true').lower() == 'true',
            min_price=float(os.getenv('SREENER_MIN_PRICE', '5.0')),
            max_price=float(os.getenv('SREENER_MAX_PRICE', '1000.0')),
            exclude_st=os.getenv('SREENER_EXCLUDE_ST', 'true').lower() == 'true',
            exclude_new_listed_days=int(os.getenv('SREENER_EXCLUDE_NEW_LISTED_DAYS', '60')),
            ai_filter_enabled=os.getenv('SREENER_AI_ENABLED', 'true').lower() == 'true',
            max_candidates=int(os.getenv('SREENER_MAX_CANDIDATES', '20')),
            final_selection=int(os.getenv('SREENER_FINAL_SELECTION', '5')),
            batch_size=int(os.getenv('SREENER_BATCH_SIZE', '100')),
            request_delay=float(os.getenv('SREENER_REQUEST_DELAY', '2.0')),
        )

    def screen_market(
        self,
        mode: ScreeningMode = ScreeningMode.FULL,
        force_refresh: bool = False,
        target_date: Optional[date] = None  # æ–°å¢å‚æ•°
    ) -> List[ScreeningResult]:
        """
        æ‰§è¡Œå…¨å¸‚åœºé€‰è‚¡ï¼ˆä¸»å…¥å£ï¼‰

        Args:
            mode: é€‰è‚¡æ¨¡å¼
            force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆNoneè¡¨ç¤ºä»Šå¤©ï¼‰

        Returns:
            é€‰è‚¡ç»“æœåˆ—è¡¨
        """
        start_time = time.time()
        # ä½¿ç”¨æŒ‡å®šæ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
        screen_date = target_date or date.today()

        logger.info("=" * 60)
        logger.info(f"å¼€å§‹å…¨å¸‚åœºé€‰è‚¡: {mode.value} æ¨¡å¼")
        logger.info(f"é€‰è‚¡æ—¥æœŸ: {screen_date}")
        logger.info("=" * 60)

        # æ£€æŸ¥æ˜¯å¦æ˜¯æœªæ¥æ—¥æœŸ
        if target_date and target_date > date.today():
            logger.error(f"ä¸èƒ½æŒ‡å®šæœªæ¥æ—¥æœŸ: {target_date}")
            raise ValueError(f"Target date cannot be in the future: {target_date}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯å‘¨æœ«ï¼ˆç®€å•åˆ¤æ–­ï¼‰
        if target_date and target_date.weekday() >= 5:
            logger.warning(f"{target_date} æ˜¯å‘¨æœ«ï¼Œå¯èƒ½æ²¡æœ‰äº¤æ˜“æ•°æ®")

        # æ£€æŸ¥æ˜¯å¦å·²é€‰è‚¡
        if not force_refresh and self._has_today_screening(screen_date):
            logger.info(f"{screen_date} å·²æ‰§è¡Œé€‰è‚¡ï¼Œä½¿ç”¨ç¼“å­˜ç»“æœ")
            return self._load_screening_results_by_date(screen_date)

        # Step 1: è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨
        all_stocks = self._get_all_stocks(target_date=target_date)
        logger.info(f"å…¨å¸‚åœºè‚¡ç¥¨æ•°: {len(all_stocks)}")

        if not all_stocks:
            logger.warning("æœªè·å–åˆ°è‚¡ç¥¨åˆ—è¡¨ï¼Œé€‰è‚¡ç»ˆæ­¢")
            return []

        # Step 2: æŠ€æœ¯æŒ‡æ ‡ç­›é€‰ï¼ˆç¬¬ä¸€å±‚ï¼‰
        tech_candidates = []
        if mode in [ScreeningMode.TECH_ONLY, ScreeningMode.FULL]:
            tech_candidates = self._technical_filter_batch(all_stocks)
            logger.info(f"æŠ€æœ¯ç­›é€‰å®Œæˆ: {len(all_stocks)} â†’ {len(tech_candidates)}")

            if mode == ScreeningMode.TECH_ONLY:
                # ä»…æŠ€æœ¯æ¨¡å¼ï¼Œç›´æ¥è¿”å›
                results = self._build_screening_results(tech_candidates)
                self._save_screening_results(results, screen_date)
                logger.info(f"é€‰è‚¡å®Œæˆï¼ˆä»…æŠ€æœ¯ï¼‰: å…± {len(results)} åªè‚¡ç¥¨")
                return results
        elif mode == ScreeningMode.AI_ONLY:
            # AIæ¨¡å¼ï¼Œè·³è¿‡æŠ€æœ¯ç­›é€‰
            tech_candidates = all_stocks[:self.criteria.max_candidates]

        # Step 3: AIæ™ºèƒ½ç­›é€‰ï¼ˆç¬¬äºŒå±‚ï¼‰
        final_results = []
        if self.criteria.ai_filter_enabled and mode in [ScreeningMode.AI_ONLY, ScreeningMode.FULL]:
            # é™åˆ¶å€™é€‰æ•°é‡
            limited_candidates = tech_candidates[:self.criteria.max_candidates]
            logger.info(f"å¼€å§‹AIç­›é€‰: å€™é€‰æ•° {len(limited_candidates)}")

            final_results = self._ai_filter(limited_candidates)
            logger.info(f"AIç­›é€‰å®Œæˆ: {len(limited_candidates)} â†’ {len(final_results)}")
        else:
            # ä¸å¯ç”¨AIç­›é€‰ï¼Œè¿”å›æŠ€æœ¯ç­›é€‰ç»“æœ
            final_results = self._build_screening_results(tech_candidates)

        # Step 4: ä¿å­˜ç»“æœ
        self._save_screening_results(final_results, screen_date)

        elapsed = time.time() - start_time
        logger.info("=" * 60)
        logger.info(f"é€‰è‚¡å®Œæˆ! è€—æ—¶: {elapsed:.1f}ç§’, æœ€ç»ˆé€‰ä¸­: {len(final_results)} åªè‚¡ç¥¨")
        logger.info("=" * 60)

        # è¾“å‡ºç»“æœæ‘˜è¦
        for r in final_results:
            logger.info(f"  {r.name}({r.code}): æŠ€æœ¯è¯„åˆ†={r.tech_score:.1f}, "
                       f"AIå»ºè®®={r.ai_result.operation_advice if r.ai_result else 'N/A'}")

        return final_results

    def _get_all_stocks(self, target_date: Optional[date] = None) -> List[Dict[str, Any]]:
        """
        è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨ï¼ˆå¤ç”¨å®æ—¶è¡Œæƒ…ç¼“å­˜ï¼‰

        ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨æ£€æŸ¥æ˜¯å¦å·²æœ‰å…¨å¸‚åœºæ•°æ®ï¼Œé¿å…é‡å¤APIè°ƒç”¨

        Args:
            target_date: ç›®æ ‡æ—¥æœŸï¼ˆç”¨äºå†å²æ•°æ®æ£€æŸ¥ï¼‰

        Returns:
            è‚¡ç¥¨åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {code, name, price, ...}
        """
        # å¦‚æœæ˜¯å†å²æ—¥æœŸï¼Œè®°å½•è­¦å‘Š
        if target_date and target_date < date.today():
            logger.info(f"ä½¿ç”¨å†å²æ—¥æœŸ {target_date} è¿›è¡Œé€‰è‚¡")
            logger.warning("å†å²æ—¥æœŸé€‰è‚¡ä¾èµ–äºæ•°æ®åº“ä¸­å·²æœ‰çš„å†å²æ•°æ®ï¼Œå¦‚æ•°æ®ç¼ºå¤±å¯èƒ½å½±å“é€‰è‚¡ç»“æœ")

        try:
            import akshare as ak
            from data_provider.data_cache_manager import get_cache_manager

            cache_mgr = get_cache_manager()
            ALL_MARKET_KEY = "__all_market_spot__"

            # æ£€æŸ¥ç¼“å­˜
            df = cache_mgr.get('market', ALL_MARKET_KEY)

            if df is None:
                # ç¼“å­˜æœªå‘½ä¸­ï¼Œè·å–æ–°æ•°æ®
                self.fetcher._set_random_user_agent()
                self.fetcher._enforce_rate_limit()

                logger.info("è°ƒç”¨ ak.stock_zh_a_spot_em() è·å–å…¨å¸‚åœºè¡Œæƒ…...")
                df = ak.stock_zh_a_spot_em()

                # å­˜å…¥ç¼“å­˜ï¼ˆ60ç§’TTLï¼‰
                cache_mgr.set('market', ALL_MARKET_KEY, df)
            else:
                logger.info("[ç¼“å­˜å‘½ä¸­] ä½¿ç”¨ç¼“å­˜çš„å…¨å¸‚åœºè¡Œæƒ…æ•°æ®")

            if df is None or df.empty:
                logger.error("è·å–å…¨å¸‚åœºè¡Œæƒ…å¤±è´¥: è¿”å›ç©ºæ•°æ®")
                return []

            logger.info(f"è·å–æˆåŠŸ: å…± {len(df)} åªè‚¡ç¥¨")

            # è½¬æ¢ä¸ºå­—å…¸åˆ—è¡¨
            stocks = []
            for _, row in df.iterrows():
                code = str(row.get('ä»£ç ', ''))
                name = str(row.get('åç§°', ''))
                price = float(row.get('æœ€æ–°ä»·', 0))

                # åŸºç¡€è¿‡æ»¤
                if self._should_exclude_stock(code, name, price):
                    continue

                stocks.append({
                    'code': code,
                    'name': name,
                    'price': price,
                    'change_pct': float(row.get('æ¶¨è·Œå¹…', 0)),
                    'volume_ratio': float(row.get('é‡æ¯”', 0)),
                    'turnover_rate': float(row.get('æ¢æ‰‹ç‡', 0)),
                    'amplitude': float(row.get('æŒ¯å¹…', 0)),
                    'pe_ratio': float(row.get('å¸‚ç›ˆç‡-åŠ¨æ€', 0)),
                    'pb_ratio': float(row.get('å¸‚å‡€ç‡', 0)),
                    'total_mv': float(row.get('æ€»å¸‚å€¼', 0)),
                    'circ_mv': float(row.get('æµé€šå¸‚å€¼', 0)),
                })

            logger.info(f"åŸºç¡€è¿‡æ»¤å: {len(stocks)} åªè‚¡ç¥¨")
            return stocks

        except Exception as e:
            logger.error(f"è·å–å…¨å¸‚åœºè‚¡ç¥¨å¤±è´¥: {e}")
            return []

    def _should_exclude_stock(self, code: str, name: str, price: float) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥æ’é™¤è¯¥è‚¡ç¥¨"""
        # æ’é™¤STè‚¡ç¥¨
        if self.criteria.exclude_st and ('ST' in name or 'st' in name):
            return True

        # ä»·æ ¼è¿‡æ»¤
        if price < self.criteria.min_price or price > self.criteria.max_price:
            return True

        # æ’é™¤ç§‘åˆ›æ¿å’ŒåŒ—äº¤æ‰€ï¼ˆå¯é€‰ï¼Œæ ¹æ®éœ€è¦ï¼‰
        if code.startswith('688') or code.startswith('8') or code.startswith('4'):
            # å¯ä»¥æ ¹æ®éœ€è¦å†³å®šæ˜¯å¦æ’é™¤
            pass

        return False

    def _technical_filter_batch(self, stocks: List[Dict]) -> List[Tuple[Dict, float, List[str]]]:
        """
        æ‰¹é‡æŠ€æœ¯æŒ‡æ ‡ç­›é€‰

        Args:
            stocks: è‚¡ç¥¨åˆ—è¡¨

        Returns:
            é€šè¿‡ç­›é€‰çš„è‚¡ç¥¨åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º (stock_info, score, reasons)
        """
        candidates = []

        # åˆ†æ‰¹å¤„ç†
        batch_size = self.criteria.batch_size
        total = len(stocks)

        for i in range(0, total, batch_size):
            batch = stocks[i:i + batch_size]
            logger.info(f"æŠ€æœ¯ç­›é€‰è¿›åº¦: {i+1}-{min(i+batch_size, total)}/{total}")

            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘å¤„ç†
            with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
                futures = {
                    executor.submit(self._technical_filter, stock): stock
                    for stock in batch
                }

                for future in as_completed(futures):
                    stock = futures[future]
                    try:
                        result = future.result()
                        if result is not None:
                            score, reasons = result
                            candidates.append((stock, score, reasons))
                    except Exception as e:
                        logger.warning(f"æŠ€æœ¯ç­›é€‰ {stock['code']} å¤±è´¥: {e}")

            # æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if i + batch_size < total:
                delay = self.criteria.request_delay + random.uniform(0, 1)
                logger.debug(f"æ‰¹æ¬¡é—´ç­‰å¾… {delay:.1f} ç§’...")
                time.sleep(delay)

        # æŒ‰è¯„åˆ†æ’åº
        candidates.sort(key=lambda x: x[1], reverse=True)
        return candidates

    def _technical_filter(self, stock: Dict) -> Optional[Tuple[float, List[str]]]:
        """
        æŠ€æœ¯æŒ‡æ ‡ç­›é€‰ï¼ˆå•åªè‚¡ç¥¨ï¼‰

        ç¬¬ä¸€å±‚ç­›é€‰ï¼šåŸºäºå®æ—¶è¡Œæƒ…æ•°æ®å¿«é€Ÿç­›é€‰

        è¯„åˆ†ç»´åº¦ï¼ˆ0-100åˆ†ï¼‰ï¼š
        1. åŸºç¡€æ¡ä»¶è¿‡æ»¤ï¼ˆå¿…é¡»æ»¡è¶³ï¼‰
        2. é‡ä»·é…åˆï¼ˆ40åˆ†ï¼‰
        3. è¶‹åŠ¿åˆ¤æ–­ï¼ˆ60åˆ†ï¼‰

        Args:
            stock: è‚¡ç¥¨ä¿¡æ¯å­—å…¸

        Returns:
            (è¯„åˆ†, ç†ç”±åˆ—è¡¨) æˆ– Noneï¼ˆä¸æ»¡è¶³æ¡ä»¶ï¼‰
        """
        code = stock['code']
        name = stock['name']

        try:
            # ========== åŸºç¡€æ¡ä»¶è¿‡æ»¤ ==========
            reasons = []
            score = 0

            # æ¢æ‰‹ç‡è¿‡æ»¤
            turnover = stock.get('turnover_rate', 0)
            if turnover < self.criteria.min_turnover:
                return None  # æ¢æ‰‹ç‡è¿‡ä½

            # é‡æ¯”è¿‡æ»¤
            volume_ratio = stock.get('volume_ratio', 0)
            if volume_ratio < self.criteria.min_volume_ratio or volume_ratio > self.criteria.max_volume_ratio:
                return None  # é‡æ¯”ä¸åœ¨åˆç†åŒºé—´

            # ========== é‡ä»·é…åˆè¯„åˆ†ï¼ˆ40åˆ†ï¼‰ ==========
            # é‡æ¯”è¯„åˆ†ï¼ˆ20åˆ†ï¼‰
            if 0.8 <= volume_ratio <= 1.5:
                score += 20
                reasons.append("é‡æ¯”é€‚ä¸­(0.8-1.5)")
            elif 1.5 < volume_ratio <= 2.0:
                score += 15
                reasons.append("æ¸©å’Œæ”¾é‡")
            elif 0.5 <= volume_ratio < 0.8:
                score += 10
                reasons.append("é‡èƒ½ç•¥å¾®èç¼©")
            else:
                score += 5

            # æ¶¨è·Œå¹…è¯„åˆ†ï¼ˆ20åˆ†ï¼‰
            change_pct = stock.get('change_pct', 0)
            if -2 <= change_pct <= 5:
                score += 20
                reasons.append(f"æ¶¨è·Œå¹…åˆç†({change_pct:+.1f}%)")
            elif -5 <= change_pct < -2:
                score += 15
                reasons.append("å°å¹…å›è°ƒ")
            elif 5 < change_pct <= 8:
                score += 10
                reasons.append("æ¶¨å¹…è¾ƒå¤§")
            else:
                score += 5

            # ========== è¶‹åŠ¿åˆ¤æ–­è¯„åˆ†ï¼ˆ60åˆ†ï¼‰==========
            # ä¼˜å…ˆä½¿ç”¨æ•°æ®åº“å†å²æ•°æ®ï¼Œé¿å…é‡å¤APIè°ƒç”¨
            try:
                df = None
                from_db = False

                # å…ˆå°è¯•ä»æ•°æ®åº“è·å–å†å²æ•°æ®
                try:
                    context = self.db.get_analysis_context(code)
                    if context and 'raw_data' in context:
                        raw_data = context['raw_data']
                        if isinstance(raw_data, list) and len(raw_data) >= 20:
                            # æ•°æ®åº“ä¸­æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
                            df = pd.DataFrame(raw_data)
                            from_db = True
                            logger.debug(f"[{code}] ä½¿ç”¨æ•°æ®åº“å†å²æ•°æ® ({len(df)}æ¡)")
                except Exception as db_err:
                    logger.debug(f"[{code}] æ•°æ®åº“è¯»å–å¤±è´¥: {db_err}")

                # å¦‚æœæ•°æ®åº“æ•°æ®ä¸è¶³ï¼Œä»APIè·å–
                if df is None or df.empty or len(df) < 20:
                    df = self.fetcher.get_daily_data(code, days=30)

                if df is None or df.empty or len(df) < 20:
                    # æ•°æ®ä¸è¶³ï¼ŒåŸºäºå®æ—¶æ•°æ®ç®€å•åˆ¤æ–­
                    if change_pct > 0:
                        score += 30
                        reasons.append("å½“æ—¥ä¸Šæ¶¨")
                    else:
                        score += 20
                        reasons.append("å½“æ—¥ä¸‹è·Œ")
                else:
                    # ä½¿ç”¨è¶‹åŠ¿åˆ†æå™¨
                    trend_result = self.trend_analyzer.analyze(df, code)

                    # è¶‹åŠ¿çŠ¶æ€è¯„åˆ†ï¼ˆ40åˆ†ï¼‰
                    if trend_result.trend_status.value in ['å¼ºåŠ¿å¤šå¤´', 'å¤šå¤´æ’åˆ—']:
                        score += 40
                        reasons.append(f"å¤šå¤´æ’åˆ—({trend_result.ma_alignment})")
                    elif trend_result.trend_status.value == 'å¼±åŠ¿å¤šå¤´':
                        score += 25
                        reasons.append("å¼±åŠ¿å¤šå¤´")
                    elif trend_result.trend_status.value == 'ç›˜æ•´':
                        score += 15
                        reasons.append("å‡çº¿ç¼ ç»•")
                    else:
                        score += 5
                        reasons.append("ç©ºå¤´æ’åˆ—")

                    # ä¹–ç¦»ç‡è¯„åˆ†ï¼ˆ20åˆ†ï¼‰
                    bias_ma5 = trend_result.bias_ma5
                    if abs(bias_ma5) < 2:
                        score += 20
                        reasons.append(f"ä¹–ç¦»ç‡å®‰å…¨({bias_ma5:+.1f}%)")
                    elif abs(bias_ma5) < self.criteria.max_bias_ma5:
                        score += 15
                        reasons.append(f"ä¹–ç¦»ç‡å¯æ¥å—({bias_ma5:+.1f}%)")
                    else:
                        score += 5
                        reasons.append(f"ä¹–ç¦»ç‡è¾ƒé«˜({bias_ma5:+.1f}%)")

                    # æ›´æ–°è‚¡ç¥¨ä¿¡æ¯ï¼ˆæ·»åŠ å‡çº¿æ•°æ®ï¼‰
                    stock['ma5'] = trend_result.ma5
                    stock['ma10'] = trend_result.ma10
                    stock['ma20'] = trend_result.ma20
                    stock['bias_ma5'] = bias_ma5

            except Exception as e:
                logger.debug(f"{code} è¶‹åŠ¿åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨ç®€å•åˆ¤æ–­")
                # è¶‹åŠ¿åˆ†æå¤±è´¥æ—¶çš„é™çº§å¤„ç†
                if change_pct > 0:
                    score += 30
                else:
                    score += 20

            # æ£€æŸ¥æœ€ä½è¯„åˆ†è¦æ±‚
            if score < self.criteria.min_trend_strength:
                return None

            return (score, reasons)

        except Exception as e:
            logger.warning(f"æŠ€æœ¯ç­›é€‰ {name}({code}) å¤±è´¥: {e}")
            return None

    def _ai_filter(self, candidates: List[Tuple[Dict, float, List[str]]]) -> List[ScreeningResult]:
        """
        AIæ™ºèƒ½ç­›é€‰ï¼ˆç¬¬äºŒå±‚ï¼‰

        å¯¹ç¬¬ä¸€å±‚é€šè¿‡è€…è¿›è¡Œæ·±åº¦åˆ†æï¼Œå¤ç”¨ç°æœ‰AIåˆ†æèƒ½åŠ›

        Args:
            candidates: ç¬¬ä¸€å±‚ç­›é€‰ç»“æœåˆ—è¡¨

        Returns:
            æœ€ç»ˆé€‰ä¸­çš„è‚¡ç¥¨åˆ—è¡¨
        """
        if not self.ai_analyzer.is_available():
            logger.warning("AIåˆ†æå™¨ä¸å¯ç”¨ï¼Œè¿”å›æŠ€æœ¯ç­›é€‰ç»“æœ")
            return self._build_screening_results(candidates)

        ai_results = []

        # é™åˆ¶åˆ†ææ•°é‡
        to_analyze = candidates[:self.criteria.max_candidates]
        logger.info(f"å¼€å§‹AIåˆ†æ: å¾…åˆ†æè‚¡ç¥¨æ•° {len(to_analyze)}")

        for i, (stock, tech_score, tech_reasons) in enumerate(to_analyze):
            code = stock['code']
            name = stock['name']

            logger.info(f"[{i+1}/{len(to_analyze)}] AIåˆ†æ {name}({code})")

            try:
                # è·å–å¢å¼ºæ•°æ®
                enhanced_data = self.fetcher.get_enhanced_data(code, days=30)
                df = enhanced_data.get('daily_data')

                if df is None or df.empty:
                    logger.warning(f"{code} æ•°æ®ä¸è¶³ï¼Œè·³è¿‡AIåˆ†æ")
                    continue

                # æ„å»ºåˆ†æä¸Šä¸‹æ–‡
                context = self._build_analysis_context(stock, df, enhanced_data)

                # æœç´¢æ–°é—»ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                news_context = None
                if self.search_service and self.search_service.is_available:
                    try:
                        intel_results = self.search_service.search_comprehensive_intel(
                            stock_code=code,
                            stock_name=name,
                            max_searches=2
                        )
                        if intel_results:
                            news_context = self.search_service.format_intel_report(intel_results, name)
                            logger.debug(f"{code} æƒ…æŠ¥æœç´¢å®Œæˆ")
                    except Exception as e:
                        logger.debug(f"{code} æƒ…æŠ¥æœç´¢å¤±è´¥: {e}")

                # AIåˆ†æ
                ai_result = self.ai_analyzer.analyze(context, news_context=news_context)

                if ai_result and ai_result.success:
                    ai_results.append((stock, tech_score, tech_reasons, ai_result))
                    logger.info(f"  â†’ AIè¯„åˆ†: {ai_result.sentiment_score}, å»ºè®®: {ai_result.operation_advice}")
                else:
                    logger.warning(f"  â†’ AIåˆ†æå¤±è´¥")

                # è¯·æ±‚é—´å»¶è¿Ÿ
                if i < len(to_analyze) - 1:
                    time.sleep(self.criteria.request_delay)

            except Exception as e:
                logger.warning(f"AIåˆ†æ {name}({code}) å¤±è´¥: {e}")

        # ç»¼åˆè¯„åˆ†æ’åº
        # ç»¼åˆè¯„åˆ† = æŠ€æœ¯è¯„åˆ† * 0.4 + AIè¯„åˆ† * 0.6
        scored_results = []
        for stock, tech_score, tech_reasons, ai_result in ai_results:
            combined_score = tech_score * 0.4 + ai_result.sentiment_score * 0.6
            scored_results.append((combined_score, stock, tech_score, tech_reasons, ai_result))

        # æŒ‰ç»¼åˆè¯„åˆ†æ’åºï¼Œå–å‰Nå
        scored_results.sort(key=lambda x: x[0], reverse=True)
        final_selected = scored_results[:self.criteria.final_selection]

        # æ„å»ºç»“æœ
        results = []
        for _, stock, tech_score, tech_reasons, ai_result in final_selected:
            results.append(ScreeningResult(
                code=stock['code'],
                name=stock['name'],
                tech_score=tech_score,
                tech_reasons=tech_reasons,
                ai_result=ai_result
            ))

        return results

    def _build_analysis_context(
        self,
        stock: Dict,
        df: pd.DataFrame,
        enhanced_data: Dict
    ) -> Dict[str, Any]:
        """æ„å»ºAIåˆ†æä¸Šä¸‹æ–‡"""
        latest = df.iloc[-1]

        context = {
            'code': stock['code'],
            'date': date.today().isoformat(),
            'stock_name': stock['name'],
            'today': {
                'open': float(latest.get('open', 0)),
                'high': float(latest.get('high', 0)),
                'low': float(latest.get('low', 0)),
                'close': float(latest.get('close', stock.get('price', 0))),
                'volume': float(latest.get('volume', 0)),
                'amount': float(latest.get('amount', 0)),
                'pct_chg': float(stock.get('change_pct', 0)),
                'ma5': float(stock.get('ma5', 0)),
                'ma10': float(stock.get('ma10', 0)),
                'ma20': float(stock.get('ma20', 0)),
            },
            'realtime': {
                'name': stock['name'],
                'price': stock.get('price', 0),
                'volume_ratio': stock.get('volume_ratio', 0),
                'turnover_rate': stock.get('turnover_rate', 0),
                'pe_ratio': stock.get('pe_ratio', 0),
                'pb_ratio': stock.get('pb_ratio', 0),
                'total_mv': stock.get('total_mv', 0),
                'circ_mv': stock.get('circ_mv', 0),
                'change_60d': stock.get('change_60d', 0),
            },
            'ma_status': self._get_ma_status(stock),
        }

        # æ·»åŠ ç­¹ç åˆ†å¸ƒæ•°æ®
        chip_data = enhanced_data.get('chip_distribution')
        if chip_data:
            context['chip'] = {
                'profit_ratio': chip_data.profit_ratio,
                'avg_cost': chip_data.avg_cost,
                'concentration_90': chip_data.concentration_90,
                'concentration_70': chip_data.concentration_70,
                'chip_status': chip_data.get_chip_status(stock.get('price', 0)),
            }

        return context

    def _get_ma_status(self, stock: Dict) -> str:
        """è·å–å‡çº¿çŠ¶æ€"""
        ma5 = stock.get('ma5', 0)
        ma10 = stock.get('ma10', 0)
        ma20 = stock.get('ma20', 0)
        price = stock.get('price', 0)

        if ma5 > ma10 > ma20 > 0:
            if price > ma5:
                return "å¤šå¤´æ’åˆ— ğŸ“ˆ"
            else:
                return "å¤šå¤´æ’åˆ—(å›è¸©)"
        elif ma5 < ma10 < ma20 and ma20 > 0:
            return "ç©ºå¤´æ’åˆ— ğŸ“‰"
        else:
            return "éœ‡è¡æ•´ç† â†”ï¸"

    def _build_screening_results(
        self,
        candidates: List[Tuple[Dict, float, List[str]]]
    ) -> List[ScreeningResult]:
        """æ„å»ºé€‰è‚¡ç»“æœï¼ˆæ— AIåˆ†æï¼‰"""
        results = []
        for stock, score, reasons in candidates[:self.criteria.final_selection]:
            results.append(ScreeningResult(
                code=stock['code'],
                name=stock['name'],
                tech_score=score,
                tech_reasons=reasons,
                ai_result=None
            ))
        return results

    def _save_screening_results(self, results: List[ScreeningResult], screen_date: Optional[date] = None) -> None:
        """ä¿å­˜é€‰è‚¡ç»“æœåˆ°æ•°æ®åº“

        Args:
            results: é€‰è‚¡ç»“æœåˆ—è¡¨
            screen_date: é€‰è‚¡æ—¥æœŸï¼ˆNoneè¡¨ç¤ºä»Šå¤©ï¼‰
        """
        if not results:
            logger.warning("æ— é€‰è‚¡ç»“æœéœ€è¦ä¿å­˜")
            return

        try:
            save_date = screen_date or date.today()
            saved_count = 0

            with self.db.get_session() as session:
                for r in results:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = session.query(ScreeningResultDB).filter(
                        and_(
                            ScreeningResultDB.code == r.code,
                            ScreeningResultDB.screen_date == save_date
                        )
                    ).first()

                    if existing:
                        # æ›´æ–°ç°æœ‰è®°å½•
                        existing.tech_score = r.tech_score
                        existing.tech_reasons = json.dumps(r.tech_reasons, ensure_ascii=False)
                        if r.ai_result:
                            existing.ai_sentiment_score = r.ai_result.sentiment_score
                            existing.ai_operation_advice = r.ai_result.operation_advice
                            existing.ai_trend_prediction = r.ai_result.trend_prediction
                            existing.ai_analysis_summary = r.ai_result.analysis_summary
                        existing.screen_time = r.screen_time
                    else:
                        # åˆ›å»ºæ–°è®°å½•
                        record = ScreeningResultDB(
                            code=r.code,
                            name=r.name,
                            tech_score=r.tech_score,
                            tech_reasons=json.dumps(r.tech_reasons, ensure_ascii=False),
                            ai_sentiment_score=r.ai_result.sentiment_score if r.ai_result else None,
                            ai_operation_advice=r.ai_result.operation_advice if r.ai_result else None,
                            ai_trend_prediction=r.ai_result.trend_prediction if r.ai_result else None,
                            ai_analysis_summary=r.ai_result.analysis_summary if r.ai_result else None,
                            screen_date=save_date,
                            screen_time=r.screen_time
                        )
                        session.add(record)
                        saved_count += 1

                session.commit()

            logger.info(f"é€‰è‚¡ç»“æœä¿å­˜æˆåŠŸ: æ–°å¢ {saved_count} æ¡")

        except Exception as e:
            logger.error(f"ä¿å­˜é€‰è‚¡ç»“æœå¤±è´¥: {e}")

    def _has_today_screening(self, today: date) -> bool:
        """æ£€æŸ¥ä»Šæ—¥æ˜¯å¦å·²æ‰§è¡Œé€‰è‚¡"""
        try:
            with self.db.get_session() as session:
                count = session.query(ScreeningResultDB).filter(
                    ScreeningResultDB.screen_date == today
                ).count()
                return count > 0
        except Exception as e:
            logger.error(f"æ£€æŸ¥ä»Šæ—¥é€‰è‚¡ç»“æœå¤±è´¥: {e}")
            return False

    def _load_screening_results_by_date(self, target_date: date) -> List[ScreeningResult]:
        """ä»æ•°æ®åº“åŠ è½½æŒ‡å®šæ—¥æœŸçš„é€‰è‚¡ç»“æœ

        Args:
            target_date: ç›®æ ‡æ—¥æœŸ

        Returns:
            é€‰è‚¡ç»“æœåˆ—è¡¨
        """
        try:
            results = []

            with self.db.get_session() as session:
                records = session.query(ScreeningResultDB).filter(
                    ScreeningResultDB.screen_date == target_date
                ).order_by(desc(ScreeningResultDB.tech_score)).all()

                for r in records:
                    # æ„å»ºAIç»“æœ
                    ai_result = None
                    if r.ai_sentiment_score is not None:
                        ai_result = AnalysisResult(
                            code=r.code,
                            name=r.name,
                            sentiment_score=r.ai_sentiment_score,
                            operation_advice=r.ai_operation_advice or 'æŒæœ‰',
                            trend_prediction=r.ai_trend_prediction or 'éœ‡è¡',
                            analysis_summary=r.ai_analysis_summary or '',
                        )

                    results.append(ScreeningResult(
                        code=r.code,
                        name=r.name,
                        tech_score=r.tech_score,
                        tech_reasons=json.loads(r.tech_reasons) if r.tech_reasons else [],
                        ai_result=ai_result,
                        screen_time=r.screen_time
                    ))

            return results

        except Exception as e:
            logger.error(f"åŠ è½½ {target_date} é€‰è‚¡ç»“æœå¤±è´¥: {e}")
            return []


# ==================== ä¾¿æ·å‡½æ•° ====================

def get_screener() -> StockScreener:
    """è·å–é€‰è‚¡å™¨å®ä¾‹"""
    return StockScreener()


def screen_stocks(
    mode: ScreeningMode = ScreeningMode.FULL,
    force_refresh: bool = False
) -> List[ScreeningResult]:
    """
    æ‰§è¡Œé€‰è‚¡çš„å¿«æ·æ–¹å¼

    Args:
        mode: é€‰è‚¡æ¨¡å¼
        force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°

    Returns:
        é€‰è‚¡ç»“æœåˆ—è¡¨
    """
    screener = get_screener()
    return screener.screen_market(mode=mode, force_refresh=force_refresh)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
    )

    # æµ‹è¯•æŠ€æœ¯ç­›é€‰
    screener = get_screener()

    # ä»…æŠ€æœ¯ç­›é€‰æµ‹è¯•
    print("\n=== æµ‹è¯•æŠ€æœ¯ç­›é€‰ ===")
    results = screener.screen_market(mode=ScreeningMode.TECH_ONLY)

    for r in results:
        print(f"{r.name}({r.code}): æŠ€æœ¯è¯„åˆ†={r.tech_score:.1f}")
        print(f"  ç†ç”±: {', '.join(r.tech_reasons)}")
