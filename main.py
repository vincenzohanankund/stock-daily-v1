# -*- coding: utf-8 -*-
"""
===================================
Aè‚¡è‡ªé¸è‚¡æ™ºèƒ½åˆ†æç³»çµ± - ä¸»èª¿åº¦ç¨‹åº
===================================

è·è²¬ï¼š
1. å”èª¿å„æ¨¡å¡Šå®Œæˆè‚¡ç¥¨åˆ†ææµç¨‹
2. å¯¦ç¾ä½ä½µç™¼çš„ç·šç¨‹æ± èª¿åº¦
3. å…¨å±€ç•°å¸¸è™•ç†ï¼Œç¢ºä¿å–®è‚¡å¤±æ•—ä¸å½±éŸ¿æ•´é«”
4. æä¾›å‘½ä»¤è¡Œå…¥å£

ä½¿ç”¨æ–¹å¼ï¼š
    python main.py              # æ­£å¸¸é‹è¡Œ
    python main.py --debug      # èª¿è©¦æ¨¡å¼
    python main.py --dry-run    # åƒ…ç²å–æ•¸æ“šä¸åˆ†æ

äº¤æ˜“ç†å¿µï¼ˆå·²èå…¥åˆ†æï¼‰ï¼š
- åš´é€²ç­–ç•¥ï¼šä¸è¿½é«˜ï¼Œä¹–é›¢ç‡ > 5% ä¸è²·å…¥
- è¶¨å‹¢äº¤æ˜“ï¼šåªåš MA5>MA10>MA20 å¤šé ­æ’åˆ—
- æ•ˆç‡å„ªå…ˆï¼šé—œæ³¨ç±Œç¢¼é›†ä¸­åº¦å¥½çš„è‚¡ç¥¨
- è²·é»åå¥½ï¼šç¸®é‡å›è¸© MA5/MA10 æ”¯æ’
"""
import os

# ä»£ç†é…ç½® - åƒ…åœ¨æœ¬åœ°ç’°å¢ƒä½¿ç”¨ï¼ŒGitHub Actions ä¸éœ€è¦
if os.getenv("GITHUB_ACTIONS") != "true":
    # æœ¬åœ°é–‹ç™¼ç’°å¢ƒï¼Œå¦‚éœ€ä»£ç†è«‹å–æ¶ˆè¨»é‡‹æˆ–ä¿®æ”¹ç«¯å£
    # os.environ["http_proxy"] = "http://127.0.0.1:10809"
    # os.environ["https_proxy"] = "http://127.0.0.1:10809"
    pass

import argparse
import logging
import sys
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, date, timezone, timedelta
from logging.handlers import RotatingFileHandler
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from feishu_doc import FeishuDocManager

from config import get_config, Config
from storage import get_db, DatabaseManager
from data_provider import DataFetcherManager
from data_provider.akshare_fetcher import AkshareFetcher, RealtimeQuote, ChipDistribution
from analyzer import GeminiAnalyzer, AnalysisResult, STOCK_NAME_MAP
from notification import NotificationService, NotificationChannel, send_daily_report
from bot.models import BotMessage
from search_service import SearchService, SearchResponse
from enums import ReportType
from stock_analyzer import StockTrendAnalyzer, TrendAnalysisResult
from market_analyzer import MarketAnalyzer

# é…ç½®æ—¥èªŒæ ¼å¼
LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(name)-20s | %(message)s'
LOG_DATE_FORMAT = '%Y-%m-%d %H:%M:%S'


def setup_logging(debug: bool = False, log_dir: str = "./logs") -> None:
    """
    é…ç½®æ—¥èªŒç³»çµ±ï¼ˆåŒæ™‚è¼¸å‡ºåˆ°æ§åˆ¶æª¯å’Œæ–‡ä»¶ï¼‰
    
    Args:
        debug: æ˜¯å¦å•Ÿç”¨èª¿è©¦æ¨¡å¼
        log_dir: æ—¥èªŒæ–‡ä»¶ç›®éŒ„
    """
    level = logging.DEBUG if debug else logging.INFO
    
    # å‰µå»ºæ—¥èªŒç›®éŒ„
    log_path = Path(log_dir)
    log_path.mkdir(parents=True, exist_ok=True)
    
    # æ—¥èªŒæ–‡ä»¶è·¯å¾‘ï¼ˆæŒ‰æ—¥æœŸåˆ†æ–‡ä»¶ï¼‰
    today_str = datetime.now().strftime('%Y%m%d')
    log_file = log_path / f"stock_analysis_{today_str}.log"
    debug_log_file = log_path / f"stock_analysis_debug_{today_str}.log"
    
    # å‰µå»ºæ ¹ logger
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.DEBUG)  # æ ¹ logger è¨­ç‚º DEBUGï¼Œç”± handler æ§åˆ¶è¼¸å‡ºç´šåˆ¥
    
    # Handler 1: æ§åˆ¶æª¯è¼¸å‡º
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(level)
    console_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(console_handler)
    
    # Handler 2: å¸¸è¦æ—¥èªŒæ–‡ä»¶ï¼ˆINFO ç´šåˆ¥ï¼Œ10MB è¼ªè½‰ï¼‰
    file_handler = RotatingFileHandler(
        log_file,
        maxBytes=10 * 1024 * 1024,  # 10MB
        backupCount=5,
        encoding='utf-8'
    )
    file_handler.setLevel(logging.INFO)
    file_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(file_handler)
    
    # Handler 3: èª¿è©¦æ—¥èªŒæ–‡ä»¶ï¼ˆDEBUG ç´šåˆ¥ï¼ŒåŒ…å«æ‰€æœ‰è©³ç´°ä¿¡æ¯ï¼‰
    debug_handler = RotatingFileHandler(
        debug_log_file,
        maxBytes=50 * 1024 * 1024,  # 50MB
        backupCount=3,
        encoding='utf-8'
    )
    debug_handler.setLevel(logging.DEBUG)
    debug_handler.setFormatter(logging.Formatter(LOG_FORMAT, LOG_DATE_FORMAT))
    root_logger.addHandler(debug_handler)
    
    # é™ä½ç¬¬ä¸‰æ–¹åº«çš„æ—¥èªŒç´šåˆ¥
    logging.getLogger('urllib3').setLevel(logging.WARNING)
    logging.getLogger('sqlalchemy').setLevel(logging.WARNING)
    logging.getLogger('google').setLevel(logging.WARNING)
    logging.getLogger('httpx').setLevel(logging.WARNING)
    
    logging.info(f"æ—¥èªŒç³»çµ±åˆå§‹åŒ–å®Œæˆï¼Œæ—¥èªŒç›®éŒ„: {log_path.absolute()}")
    logging.info(f"å¸¸è¦æ—¥èªŒ: {log_file}")
    logging.info(f"èª¿è©¦æ—¥èªŒ: {debug_log_file}")


logger = logging.getLogger(__name__)


class StockAnalysisPipeline:
    """
    è‚¡ç¥¨åˆ†æä¸»æµç¨‹èª¿åº¦å™¨
    
    è·è²¬ï¼š
    1. ç®¡ç†æ•´å€‹åˆ†ææµç¨‹
    2. å”èª¿æ•¸æ“šç²å–ã€å­˜å„²ã€æœç´¢ã€åˆ†æã€é€šçŸ¥ç­‰æ¨¡å¡Š
    3. å¯¦ç¾ä½µç™¼æ§åˆ¶å’Œç•°å¸¸è™•ç†
    """
    
    def __init__(
        self,
        config: Optional[Config] = None,
        max_workers: Optional[int] = None,
        source_message: Optional[BotMessage] = None
    ):
        """
        åˆå§‹åŒ–èª¿åº¦å™¨
        
        Args:
            config: é…ç½®å°è±¡ï¼ˆå¯é¸ï¼Œé»˜èªä½¿ç”¨å…¨å±€é…ç½®ï¼‰
            max_workers: æœ€å¤§ä½µç™¼ç·šç¨‹æ•¸ï¼ˆå¯é¸ï¼Œé»˜èªå¾é…ç½®è®€å–ï¼‰
        """
        self.config = config or get_config()
        self.max_workers = max_workers or self.config.max_workers
        self.source_message = source_message
        
        # åˆå§‹åŒ–å„æ¨¡å¡Š
        self.db = get_db()
        self.fetcher_manager = DataFetcherManager()
        self.akshare_fetcher = AkshareFetcher()  # ç”¨æ–¼ç²å–å¢å¼·æ•¸æ“šï¼ˆé‡æ¯”ã€ç±Œç¢¼ç­‰ï¼‰
        self.trend_analyzer = StockTrendAnalyzer()  # è¶¨å‹¢åˆ†æå™¨
        self.analyzer = GeminiAnalyzer()
        self.notifier = NotificationService(source_message=source_message)
        
        # åˆå§‹åŒ–æœç´¢æœå‹™
        self.search_service = SearchService(
            bocha_keys=self.config.bocha_api_keys,
            tavily_keys=self.config.tavily_api_keys,
            serpapi_keys=self.config.serpapi_keys,
        )
        
        logger.info(f"èª¿åº¦å™¨åˆå§‹åŒ–å®Œæˆï¼Œæœ€å¤§ä½µç™¼æ•¸: {self.max_workers}")
        logger.info("å·²å•Ÿç”¨è¶¨å‹¢åˆ†æå™¨ (MA5>MA10>MA20 å¤šé ­åˆ¤æ–·)")
        if self.search_service.is_available:
            logger.info("æœç´¢æœå‹™å·²å•Ÿç”¨ (Tavily/SerpAPI)")
        else:
            logger.warning("æœç´¢æœå‹™æœªå•Ÿç”¨ï¼ˆæœªé…ç½® API Keyï¼‰")
    
    def fetch_and_save_stock_data(
        self, 
        code: str,
        force_refresh: bool = False
    ) -> Tuple[bool, Optional[str]]:
        """
        ç²å–ä¸¦ä¿å­˜å–®éš»è‚¡ç¥¨æ•¸æ“š
        
        æ–·é»çºŒå‚³é‚è¼¯ï¼š
        1. æª¢æŸ¥æ•¸æ“šåº«æ˜¯å¦å·²æœ‰ä»Šæ—¥æ•¸æ“š
        2. å¦‚æœæœ‰ä¸”ä¸å¼·åˆ¶åˆ·æ–°ï¼Œå‰‡è·³éç¶²çµ¡è«‹æ±‚
        3. å¦å‰‡å¾æ•¸æ“šæºç²å–ä¸¦ä¿å­˜
        
        Args:
            code: è‚¡ç¥¨ä»£ç¢¼
            force_refresh: æ˜¯å¦å¼·åˆ¶åˆ·æ–°ï¼ˆå¿½ç•¥æœ¬åœ°ç·©å­˜ï¼‰
            
        Returns:
            Tuple[æ˜¯å¦æˆåŠŸ, éŒ¯èª¤ä¿¡æ¯]
        """
        try:
            today = date.today()
            
            # æ–·é»çºŒå‚³æª¢æŸ¥ï¼šå¦‚æœä»Šæ—¥æ•¸æ“šå·²å­˜åœ¨ï¼Œè·³é
            if not force_refresh and self.db.has_today_data(code, today):
                logger.info(f"[{code}] ä»Šæ—¥æ•¸æ“šå·²å­˜åœ¨ï¼Œè·³éç²å–ï¼ˆæ–·é»çºŒå‚³ï¼‰")
                return True, None
            
            # å¾æ•¸æ“šæºç²å–æ•¸æ“š
            logger.info(f"[{code}] é–‹å§‹å¾æ•¸æ“šæºç²å–æ•¸æ“š...")
            df, source_name = self.fetcher_manager.get_daily_data(code, days=30)
            
            if df is None or df.empty:
                return False, "ç²å–æ•¸æ“šç‚ºç©º"
            
            # ä¿å­˜åˆ°æ•¸æ“šåº«
            saved_count = self.db.save_daily_data(df, code, source_name)
            logger.info(f"[{code}] æ•¸æ“šä¿å­˜æˆåŠŸï¼ˆä¾†æº: {source_name}ï¼Œæ–°å¢ {saved_count} æ¢ï¼‰")
            
            return True, None
            
        except Exception as e:
            error_msg = f"ç²å–/ä¿å­˜æ•¸æ“šå¤±æ•—: {str(e)}"
            logger.error(f"[{code}] {error_msg}")
            return False, error_msg
    
    def analyze_stock(self, code: str) -> Optional[AnalysisResult]:
        """
        åˆ†æå–®éš»è‚¡ç¥¨ï¼ˆå¢å¼·ç‰ˆï¼šå«é‡æ¯”ã€æ›æ‰‹ç‡ã€ç±Œç¢¼åˆ†æã€å¤šç¶­åº¦æƒ…å ±ï¼‰
        
        æµç¨‹ï¼š
        1. ç²å–å¯¦æ™‚è¡Œæƒ…ï¼ˆé‡æ¯”ã€æ›æ‰‹ç‡ï¼‰
        2. ç²å–ç±Œç¢¼åˆ†ä½ˆ
        3. é€²è¡Œè¶¨å‹¢åˆ†æï¼ˆåŸºæ–¼äº¤æ˜“ç†å¿µï¼‰
        4. å¤šç¶­åº¦æƒ…å ±æœç´¢ï¼ˆæœ€æ–°æ¶ˆæ¯+é¢¨éšªæ’æŸ¥+æ¥­ç¸¾é æœŸï¼‰
        5. å¾æ•¸æ“šåº«ç²å–åˆ†æä¸Šä¸‹æ–‡
        6. èª¿ç”¨ AI é€²è¡Œç¶œåˆåˆ†æ
        
        Args:
            code: è‚¡ç¥¨ä»£ç¢¼
            
        Returns:
            AnalysisResult æˆ– Noneï¼ˆå¦‚æœåˆ†æå¤±æ•—ï¼‰
        """
        try:
            # ç²å–è‚¡ç¥¨åç¨±ï¼ˆå„ªå…ˆå¾å¯¦æ™‚è¡Œæƒ…ç²å–çœŸå¯¦åç¨±ï¼‰
            stock_name = STOCK_NAME_MAP.get(code, '')
            
            # Step 1: ç²å–å¯¦æ™‚è¡Œæƒ…ï¼ˆé‡æ¯”ã€æ›æ‰‹ç‡ç­‰ï¼‰
            realtime_quote: Optional[RealtimeQuote] = None
            try:
                realtime_quote = self.akshare_fetcher.get_realtime_quote(code)
                if realtime_quote:
                    # ä½¿ç”¨å¯¦æ™‚è¡Œæƒ…è¿”å›çš„çœŸå¯¦è‚¡ç¥¨åç¨±
                    if realtime_quote.name:
                        stock_name = realtime_quote.name
                    logger.info(f"[{code}] {stock_name} å¯¦æ™‚è¡Œæƒ…: åƒ¹æ ¼={realtime_quote.price}, "
                              f"é‡æ¯”={realtime_quote.volume_ratio}, æ›æ‰‹ç‡={realtime_quote.turnover_rate}%")
            except Exception as e:
                logger.warning(f"[{code}] ç²å–å¯¦æ™‚è¡Œæƒ…å¤±æ•—: {e}")
            
            # å¦‚æœé‚„æ˜¯æ²’æœ‰åç¨±ï¼Œä½¿ç”¨ä»£ç¢¼ä½œç‚ºåç¨±
            if not stock_name:
                stock_name = f'è‚¡ç¥¨{code}'
            
            # Step 2: ç²å–ç±Œç¢¼åˆ†ä½ˆ
            chip_data: Optional[ChipDistribution] = None
            try:
                chip_data = self.akshare_fetcher.get_chip_distribution(code)
                if chip_data:
                    logger.info(f"[{code}] ç±Œç¢¼åˆ†ä½ˆ: ç²åˆ©æ¯”ä¾‹={chip_data.profit_ratio:.1%}, "
                              f"90%é›†ä¸­åº¦={chip_data.concentration_90:.2%}")
            except Exception as e:
                logger.warning(f"[{code}] ç²å–ç±Œç¢¼åˆ†ä½ˆå¤±æ•—: {e}")
            
            # Step 3: è¶¨å‹¢åˆ†æï¼ˆåŸºæ–¼äº¤æ˜“ç†å¿µï¼‰
            trend_result: Optional[TrendAnalysisResult] = None
            try:
                # ç²å–æ­·å²æ•¸æ“šé€²è¡Œè¶¨å‹¢åˆ†æ
                context = self.db.get_analysis_context(code)
                if context and 'raw_data' in context:
                    import pandas as pd
                    raw_data = context['raw_data']
                    if isinstance(raw_data, list) and len(raw_data) > 0:
                        df = pd.DataFrame(raw_data)
                        trend_result = self.trend_analyzer.analyze(df, code)
                        logger.info(f"[{code}] è¶¨å‹¢åˆ†æ: {trend_result.trend_status.value}, "
                                  f"è²·å…¥ä¿¡è™Ÿ={trend_result.buy_signal.value}, è©•åˆ†={trend_result.signal_score}")
            except Exception as e:
                logger.warning(f"[{code}] è¶¨å‹¢åˆ†æå¤±æ•—: {e}")
            
            # Step 4: å¤šç¶­åº¦æƒ…å ±æœç´¢ï¼ˆæœ€æ–°æ¶ˆæ¯+é¢¨éšªæ’æŸ¥+æ¥­ç¸¾é æœŸï¼‰
            news_context = None
            if self.search_service.is_available:
                logger.info(f"[{code}] é–‹å§‹å¤šç¶­åº¦æƒ…å ±æœç´¢...")
                
                # ä½¿ç”¨å¤šç¶­åº¦æœç´¢ï¼ˆæœ€å¤š3æ¬¡æœç´¢ï¼‰
                intel_results = self.search_service.search_comprehensive_intel(
                    stock_code=code,
                    stock_name=stock_name,
                    max_searches=3
                )
                
                # æ ¼å¼åŒ–æƒ…å ±å ±å‘Š
                if intel_results:
                    news_context = self.search_service.format_intel_report(intel_results, stock_name)
                    total_results = sum(
                        len(r.results) for r in intel_results.values() if r.success
                    )
                    logger.info(f"[{code}] æƒ…å ±æœç´¢å®Œæˆ: å…± {total_results} æ¢çµæœ")
                    logger.debug(f"[{code}] æƒ…å ±æœç´¢çµæœ:\n{news_context}")
            else:
                logger.info(f"[{code}] æœç´¢æœå‹™ä¸å¯ç”¨ï¼Œè·³éæƒ…å ±æœç´¢")
            
            # Step 5: ç²å–åˆ†æä¸Šä¸‹æ–‡ï¼ˆæŠ€è¡“é¢æ•¸æ“šï¼‰
            context = self.db.get_analysis_context(code)
            
            if context is None:
                logger.warning(f"[{code}] ç„¡æ³•ç²å–åˆ†æä¸Šä¸‹æ–‡ï¼Œè·³éåˆ†æ")
                return None
            
            # Step 6: å¢å¼·ä¸Šä¸‹æ–‡æ•¸æ“šï¼ˆæ·»åŠ å¯¦æ™‚è¡Œæƒ…ã€ç±Œç¢¼ã€è¶¨å‹¢åˆ†æçµæœã€è‚¡ç¥¨åç¨±ï¼‰
            enhanced_context = self._enhance_context(
                context, 
                realtime_quote, 
                chip_data, 
                trend_result,
                stock_name  # å‚³å…¥è‚¡ç¥¨åç¨±
            )
            
            # Step 7: èª¿ç”¨ AI åˆ†æï¼ˆå‚³å…¥å¢å¼·çš„ä¸Šä¸‹æ–‡å’Œæ–°èï¼‰
            result = self.analyzer.analyze(enhanced_context, news_context=news_context)
            
            return result
            
        except Exception as e:
            logger.error(f"[{code}] åˆ†æå¤±æ•—: {e}")
            logger.exception(f"[{code}] è©³ç´°éŒ¯èª¤ä¿¡æ¯:")
            return None
    
    def _enhance_context(
        self,
        context: Dict[str, Any],
        realtime_quote: Optional[RealtimeQuote],
        chip_data: Optional[ChipDistribution],
        trend_result: Optional[TrendAnalysisResult],
        stock_name: str = ""
    ) -> Dict[str, Any]:
        """
        å¢å¼·åˆ†æä¸Šä¸‹æ–‡
        
        å°‡å¯¦æ™‚è¡Œæƒ…ã€ç±Œç¢¼åˆ†ä½ˆã€è¶¨å‹¢åˆ†æçµæœã€è‚¡ç¥¨åç¨±æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­
        
        Args:
            context: åŸå§‹ä¸Šä¸‹æ–‡
            realtime_quote: å¯¦æ™‚è¡Œæƒ…æ•¸æ“š
            chip_data: ç±Œç¢¼åˆ†ä½ˆæ•¸æ“š
            trend_result: è¶¨å‹¢åˆ†æçµæœ
            stock_name: è‚¡ç¥¨åç¨±
            
        Returns:
            å¢å¼·å¾Œçš„ä¸Šä¸‹æ–‡
        """
        enhanced = context.copy()
        
        # æ·»åŠ è‚¡ç¥¨åç¨±
        if stock_name:
            enhanced['stock_name'] = stock_name
        elif realtime_quote and realtime_quote.name:
            enhanced['stock_name'] = realtime_quote.name
        
        # æ·»åŠ å¯¦æ™‚è¡Œæƒ…
        if realtime_quote:
            enhanced['realtime'] = {
                'name': realtime_quote.name,  # è‚¡ç¥¨åç¨±
                'price': realtime_quote.price,
                'volume_ratio': realtime_quote.volume_ratio,
                'volume_ratio_desc': self._describe_volume_ratio(realtime_quote.volume_ratio),
                'turnover_rate': realtime_quote.turnover_rate,
                'pe_ratio': realtime_quote.pe_ratio,
                'pb_ratio': realtime_quote.pb_ratio,
                'total_mv': realtime_quote.total_mv,
                'circ_mv': realtime_quote.circ_mv,
                'change_60d': realtime_quote.change_60d,
            }
        
        # æ·»åŠ ç±Œç¢¼åˆ†ä½ˆ
        if chip_data:
            current_price = realtime_quote.price if realtime_quote else 0
            enhanced['chip'] = {
                'profit_ratio': chip_data.profit_ratio,
                'avg_cost': chip_data.avg_cost,
                'concentration_90': chip_data.concentration_90,
                'concentration_70': chip_data.concentration_70,
                'chip_status': chip_data.get_chip_status(current_price),
            }
        
        # æ·»åŠ è¶¨å‹¢åˆ†æçµæœ
        if trend_result:
            enhanced['trend_analysis'] = {
                'trend_status': trend_result.trend_status.value,
                'ma_alignment': trend_result.ma_alignment,
                'trend_strength': trend_result.trend_strength,
                'bias_ma5': trend_result.bias_ma5,
                'bias_ma10': trend_result.bias_ma10,
                'volume_status': trend_result.volume_status.value,
                'volume_trend': trend_result.volume_trend,
                'buy_signal': trend_result.buy_signal.value,
                'signal_score': trend_result.signal_score,
                'signal_reasons': trend_result.signal_reasons,
                'risk_factors': trend_result.risk_factors,
            }
        
        return enhanced
    
    def _describe_volume_ratio(self, volume_ratio: float) -> str:
        """
        é‡æ¯”æè¿°
        
        é‡æ¯” = ç•¶å‰æˆäº¤é‡ / éå»5æ—¥å¹³å‡æˆäº¤é‡
        """
        if volume_ratio < 0.5:
            return "æ¥µåº¦èç¸®"
        elif volume_ratio < 0.8:
            return "æ˜é¡¯èç¸®"
        elif volume_ratio < 1.2:
            return "æ­£å¸¸"
        elif volume_ratio < 2.0:
            return "æº«å’Œæ”¾é‡"
        elif volume_ratio < 3.0:
            return "æ˜é¡¯æ”¾é‡"
        else:
            return "å·¨é‡"
    
    def process_single_stock(
        self, 
        code: str, 
        skip_analysis: bool = False,
        single_stock_notify: bool = False,
        report_type: ReportType = ReportType.SIMPLE
    ) -> Optional[AnalysisResult]:
        """
        è™•ç†å–®éš»è‚¡ç¥¨çš„å®Œæ•´æµç¨‹
        
        åŒ…æ‹¬ï¼š
        1. ç²å–æ•¸æ“š
        2. ä¿å­˜æ•¸æ“š
        3. AI åˆ†æ
        4. å–®è‚¡æ¨é€ï¼ˆå¯é¸ï¼Œ#55ï¼‰
        
        æ­¤æ–¹æ³•æœƒè¢«ç·šç¨‹æ± èª¿ç”¨ï¼Œéœ€è¦è™•ç†å¥½ç•°å¸¸
        
        Args:
            code: è‚¡ç¥¨ä»£ç¢¼
            skip_analysis: æ˜¯å¦è·³é AI åˆ†æ
            single_stock_notify: æ˜¯å¦å•Ÿç”¨å–®è‚¡æ¨é€æ¨¡å¼ï¼ˆæ¯åˆ†æå®Œä¸€éš»ç«‹å³æ¨é€ï¼‰
            report_type: å ±å‘Šé¡å‹æšèˆ‰
            
        Returns:
            AnalysisResult æˆ– None
        """
        logger.info(f"========== é–‹å§‹è™•ç† {code} ==========")
        
        try:
            # Step 1: ç²å–ä¸¦ä¿å­˜æ•¸æ“š
            success, error = self.fetch_and_save_stock_data(code)
            
            if not success:
                logger.warning(f"[{code}] æ•¸æ“šç²å–å¤±æ•—: {error}")
                # å³ä½¿ç²å–å¤±æ•—ï¼Œä¹Ÿå˜—è©¦ç”¨å·²æœ‰æ•¸æ“šåˆ†æ
            
            # Step 2: AI åˆ†æ
            if skip_analysis:
                logger.info(f"[{code}] è·³é AI åˆ†æï¼ˆdry-run æ¨¡å¼ï¼‰")
                return None
            
            result = self.analyze_stock(code)
            
            if result:
                logger.info(
                    f"[{code}] åˆ†æå®Œæˆ: {result.operation_advice}, "
                    f"è©•åˆ† {result.sentiment_score}"
                )
                
                # å–®è‚¡æ¨é€æ¨¡å¼ï¼ˆ#55ï¼‰ï¼šæ¯åˆ†æå®Œä¸€éš»è‚¡ç¥¨ç«‹å³æ¨é€
                if single_stock_notify and self.notifier.is_available():
                    try:
                        # æ ¹æ“šå ±å‘Šé¡å‹é¸æ“‡ç”Ÿæˆæ–¹æ³•
                        if report_type == ReportType.FULL:
                            # å®Œæ•´å ±å‘Šï¼šä½¿ç”¨æ±ºç­–å„€è¡¨ç›¤æ ¼å¼
                            report_content = self.notifier.generate_dashboard_report([result])
                            logger.info(f"[{code}] ä½¿ç”¨å®Œæ•´å ±å‘Šæ ¼å¼")
                        else:
                            # ç²¾ç°¡å ±å‘Šï¼šä½¿ç”¨å–®è‚¡å ±å‘Šæ ¼å¼ï¼ˆé»˜èªï¼‰
                            report_content = self.notifier.generate_single_stock_report(result)
                            logger.info(f"[{code}] ä½¿ç”¨ç²¾ç°¡å ±å‘Šæ ¼å¼")
                        
                        if self.notifier.send(report_content):
                            logger.info(f"[{code}] å–®è‚¡æ¨é€æˆåŠŸ")
                        else:
                            logger.warning(f"[{code}] å–®è‚¡æ¨é€å¤±æ•—")
                    except Exception as e:
                        logger.error(f"[{code}] å–®è‚¡æ¨é€ç•°å¸¸: {e}")
            
            return result
            
        except Exception as e:
            # æ•ç²æ‰€æœ‰ç•°å¸¸ï¼Œç¢ºä¿å–®è‚¡å¤±æ•—ä¸å½±éŸ¿æ•´é«”
            logger.exception(f"[{code}] è™•ç†éç¨‹ç™¼ç”ŸæœªçŸ¥ç•°å¸¸: {e}")
            return None
    
    def run(
        self, 
        stock_codes: Optional[List[str]] = None,
        dry_run: bool = False,
        send_notification: bool = True
    ) -> List[AnalysisResult]:
        """
        é‹è¡Œå®Œæ•´çš„åˆ†ææµç¨‹
        
        æµç¨‹ï¼š
        1. ç²å–å¾…åˆ†æçš„è‚¡ç¥¨åˆ—è¡¨
        2. ä½¿ç”¨ç·šç¨‹æ± ä½µç™¼è™•ç†
        3. æ”¶é›†åˆ†æçµæœ
        4. ç™¼é€é€šçŸ¥
        
        Args:
            stock_codes: è‚¡ç¥¨ä»£ç¢¼åˆ—è¡¨ï¼ˆå¯é¸ï¼Œé»˜èªä½¿ç”¨é…ç½®ä¸­çš„è‡ªé¸è‚¡ï¼‰
            dry_run: æ˜¯å¦åƒ…ç²å–æ•¸æ“šä¸åˆ†æ
            send_notification: æ˜¯å¦ç™¼é€æ¨é€é€šçŸ¥
            
        Returns:
            åˆ†æçµæœåˆ—è¡¨
        """
        start_time = time.time()
        
        # ä½¿ç”¨é…ç½®ä¸­çš„è‚¡ç¥¨åˆ—è¡¨
        if stock_codes is None:
            self.config.refresh_stock_list()
            stock_codes = self.config.stock_list
        
        if not stock_codes:
            logger.error("æœªé…ç½®è‡ªé¸è‚¡åˆ—è¡¨ï¼Œè«‹åœ¨ .env æ–‡ä»¶ä¸­è¨­ç½® STOCK_LIST")
            return []
        
        logger.info(f"===== é–‹å§‹åˆ†æ {len(stock_codes)} åªè‚¡ç¥¨ =====")
        logger.info(f"è‚¡ç¥¨åˆ—è¡¨: {', '.join(stock_codes)}")
        logger.info(f"ä½µç™¼æ•¸: {self.max_workers}, æ¨¡å¼: {'åƒ…ç²å–æ•¸æ“š' if dry_run else 'å®Œæ•´åˆ†æ'}")
        
        # å–®è‚¡æ¨é€æ¨¡å¼ï¼ˆ#55ï¼‰ï¼šå¾é…ç½®è®€å–
        single_stock_notify = getattr(self.config, 'single_stock_notify', False)
        if single_stock_notify:
            logger.info("å·²å•Ÿç”¨å–®è‚¡æ¨é€æ¨¡å¼ï¼šæ¯åˆ†æå®Œä¸€éš»è‚¡ç¥¨ç«‹å³æ¨é€")
        
        results: List[AnalysisResult] = []
        
        # ä½¿ç”¨ç·šç¨‹æ± ä½µç™¼è™•ç†
        # æ³¨æ„ï¼šmax_workers è¨­ç½®è¼ƒä½ï¼ˆé»˜èª3ï¼‰ä»¥é¿å…è§¸ç™¼åçˆ¬
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤ä»»å‹™
            future_to_code = {
                executor.submit(
                    self.process_single_stock, 
                    code, 
                    skip_analysis=dry_run,
                    single_stock_notify=single_stock_notify and send_notification
                ): code
                for code in stock_codes
            }
            
            # æ”¶é›†çµæœ
            for future in as_completed(future_to_code):
                code = future_to_code[future]
                try:
                    result = future.result()
                    if result:
                        results.append(result)
                except Exception as e:
                    logger.error(f"[{code}] ä»»å‹™åŸ·è¡Œå¤±æ•—: {e}")
        
        # çµ±è¨ˆ
        elapsed_time = time.time() - start_time
        
        # dry-run æ¨¡å¼ä¸‹ï¼Œæ•¸æ“šç²å–æˆåŠŸå³è¦–ç‚ºæˆåŠŸ
        if dry_run:
            # æª¢æŸ¥å“ªäº›è‚¡ç¥¨çš„æ•¸æ“šä»Šå¤©å·²å­˜åœ¨
            success_count = sum(1 for code in stock_codes if self.db.has_today_data(code))
            fail_count = len(stock_codes) - success_count
        else:
            success_count = len(results)
            fail_count = len(stock_codes) - success_count
        
        logger.info(f"===== åˆ†æå®Œæˆ =====")
        logger.info(f"æˆåŠŸ: {success_count}, å¤±æ•—: {fail_count}, è€—æ™‚: {elapsed_time:.2f} ç§’")
        
        # ç™¼é€é€šçŸ¥ï¼ˆå–®è‚¡æ¨é€æ¨¡å¼ä¸‹è·³éå½™ç¸½æ¨é€ï¼Œé¿å…é‡è¤‡ï¼‰
        if results and send_notification and not dry_run:
            if single_stock_notify:
                # å–®è‚¡æ¨é€æ¨¡å¼ï¼šåªä¿å­˜å½™ç¸½å ±å‘Šï¼Œä¸å†é‡è¤‡æ¨é€
                logger.info("å–®è‚¡æ¨é€æ¨¡å¼ï¼šè·³éå½™ç¸½æ¨é€ï¼Œåƒ…ä¿å­˜å ±å‘Šåˆ°æœ¬åœ°")
                self._send_notifications(results, skip_push=True)
            else:
                self._send_notifications(results)
        
        return results
    
    def _send_notifications(self, results: List[AnalysisResult], skip_push: bool = False) -> None:
        """
        ç™¼é€åˆ†æçµæœé€šçŸ¥
        
        ç”Ÿæˆæ±ºç­–å„€è¡¨ç›¤æ ¼å¼çš„å ±å‘Š
        
        Args:
            results: åˆ†æçµæœåˆ—è¡¨
            skip_push: æ˜¯å¦è·³éæ¨é€ï¼ˆåƒ…ä¿å­˜åˆ°æœ¬åœ°ï¼Œç”¨æ–¼å–®è‚¡æ¨é€æ¨¡å¼ï¼‰
        """
        try:
            logger.info("ç”Ÿæˆæ±ºç­–å„€è¡¨ç›¤æ—¥å ±...")
            
            # ç”Ÿæˆæ±ºç­–å„€è¡¨ç›¤æ ¼å¼çš„è©³ç´°æ—¥å ±
            report = self.notifier.generate_dashboard_report(results)
            
            # ä¿å­˜åˆ°æœ¬åœ°
            filepath = self.notifier.save_report_to_file(report)
            logger.info(f"æ±ºç­–å„€è¡¨ç›¤æ—¥å ±å·²ä¿å­˜: {filepath}")
            
            # è·³éæ¨é€ï¼ˆå–®è‚¡æ¨é€æ¨¡å¼ï¼‰
            if skip_push:
                return
            
            # æ¨é€é€šçŸ¥
            if self.notifier.is_available():
                channels = self.notifier.get_available_channels()
                context_success = self.notifier.send_to_context(report)

                # ä¼æ¥­å¾®ä¿¡ï¼šåªç™¼ç²¾ç°¡ç‰ˆï¼ˆå¹³è‡ºé™åˆ¶ï¼‰
                wechat_success = False
                if NotificationChannel.WECHAT in channels:
                    dashboard_content = self.notifier.generate_wechat_dashboard(results)
                    logger.info(f"ä¼æ¥­å¾®ä¿¡å„€è¡¨ç›¤é•·åº¦: {len(dashboard_content)} å­—ç¬¦")
                    logger.debug(f"ä¼æ¥­å¾®ä¿¡æ¨é€å…§å®¹:\n{dashboard_content}")
                    wechat_success = self.notifier.send_to_wechat(dashboard_content)

                # å…¶ä»–æ¸ é“ï¼šç™¼å®Œæ•´å ±å‘Šï¼ˆé¿å…è‡ªå®šç¾© Webhook è¢« wechat æˆªæ–·é‚è¼¯æ±™æŸ“ï¼‰
                non_wechat_success = False
                for channel in channels:
                    if channel == NotificationChannel.WECHAT:
                        continue
                    if channel == NotificationChannel.FEISHU:
                        non_wechat_success = self.notifier.send_to_feishu(report) or non_wechat_success
                    elif channel == NotificationChannel.TELEGRAM:
                        non_wechat_success = self.notifier.send_to_telegram(report) or non_wechat_success
                    elif channel == NotificationChannel.EMAIL:
                        non_wechat_success = self.notifier.send_to_email(report) or non_wechat_success
                    elif channel == NotificationChannel.CUSTOM:
                        non_wechat_success = self.notifier.send_to_custom(report) or non_wechat_success
                    else:
                        logger.warning(f"æœªçŸ¥é€šçŸ¥æ¸ é“: {channel}")

                success = wechat_success or non_wechat_success or context_success
                if success:
                    logger.info("æ±ºç­–å„€è¡¨ç›¤æ¨é€æˆåŠŸ")
                else:
                    logger.warning("æ±ºç­–å„€è¡¨ç›¤æ¨é€å¤±æ•—")
            else:
                logger.info("é€šçŸ¥æ¸ é“æœªé…ç½®ï¼Œè·³éæ¨é€")
                
        except Exception as e:
            logger.error(f"ç™¼é€é€šçŸ¥å¤±æ•—: {e}")


def parse_arguments() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œåƒæ•¸"""
    parser = argparse.ArgumentParser(
        description='Aè‚¡è‡ªé¸è‚¡æ™ºèƒ½åˆ†æç³»çµ±',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹:
  python main.py                    # æ­£å¸¸é‹è¡Œ
  python main.py --debug            # èª¿è©¦æ¨¡å¼
  python main.py --dry-run          # åƒ…ç²å–æ•¸æ“šï¼Œä¸é€²è¡Œ AI åˆ†æ
  python main.py --stocks 600519,000001  # æŒ‡å®šåˆ†æç‰¹å®šè‚¡ç¥¨
  python main.py --no-notify        # ä¸ç™¼é€æ¨é€é€šçŸ¥
  python main.py --single-notify    # å•Ÿç”¨å–®è‚¡æ¨é€æ¨¡å¼ï¼ˆæ¯åˆ†æå®Œä¸€éš»ç«‹å³æ¨é€ï¼‰
  python main.py --schedule         # å•Ÿç”¨å®šæ™‚ä»»å‹™æ¨¡å¼
  python main.py --market-review    # åƒ…é‹è¡Œå¤§ç›¤è¦†ç›¤
        '''
    )
    
    parser.add_argument(
        '--debug',
        action='store_true',
        help='å•Ÿç”¨èª¿è©¦æ¨¡å¼ï¼Œè¼¸å‡ºè©³ç´°æ—¥èªŒ'
    )
    
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='åƒ…ç²å–æ•¸æ“šï¼Œä¸é€²è¡Œ AI åˆ†æ'
    )
    
    parser.add_argument(
        '--stocks',
        type=str,
        help='æŒ‡å®šè¦åˆ†æçš„è‚¡ç¥¨ä»£ç¢¼ï¼Œé€—è™Ÿåˆ†éš”ï¼ˆè¦†è“‹é…ç½®æ–‡ä»¶ï¼‰'
    )
    
    parser.add_argument(
        '--no-notify',
        action='store_true',
        help='ä¸ç™¼é€æ¨é€é€šçŸ¥'
    )
    
    parser.add_argument(
        '--single-notify',
        action='store_true',
        help='å•Ÿç”¨å–®è‚¡æ¨é€æ¨¡å¼ï¼šæ¯åˆ†æå®Œä¸€éš»è‚¡ç¥¨ç«‹å³æ¨é€ï¼Œè€Œä¸æ˜¯å½™ç¸½æ¨é€'
    )
    
    parser.add_argument(
        '--workers',
        type=int,
        default=None,
        help='ä½µç™¼ç·šç¨‹æ•¸ï¼ˆé»˜èªä½¿ç”¨é…ç½®å€¼ï¼‰'
    )
    
    parser.add_argument(
        '--schedule',
        action='store_true',
        help='å•Ÿç”¨å®šæ™‚ä»»å‹™æ¨¡å¼ï¼Œæ¯æ—¥å®šæ™‚åŸ·è¡Œ'
    )
    
    parser.add_argument(
        '--market-review',
        action='store_true',
        help='åƒ…é‹è¡Œå¤§ç›¤è¦†ç›¤åˆ†æ'
    )
    
    parser.add_argument(
        '--no-market-review',
        action='store_true',
        help='è·³éå¤§ç›¤è¦†ç›¤åˆ†æ'
    )
    
    parser.add_argument(
        '--webui',
        action='store_true',
        help='å•Ÿå‹•æœ¬åœ°é…ç½® WebUI'
    )
    
    parser.add_argument(
        '--webui-only',
        action='store_true',
        help='åƒ…å•Ÿå‹• WebUI æœå‹™ï¼Œä¸è‡ªå‹•åŸ·è¡Œåˆ†æï¼ˆé€šé /analysis API æ‰‹å‹•è§¸ç™¼ï¼‰'
    )
    
    return parser.parse_args()


def run_market_review(notifier: NotificationService, analyzer=None, search_service=None) -> Optional[str]:
    """
    åŸ·è¡Œå¤§ç›¤è¦†ç›¤åˆ†æ
    
    Args:
        notifier: é€šçŸ¥æœå‹™
        analyzer: AIåˆ†æå™¨ï¼ˆå¯é¸ï¼‰
        search_service: æœç´¢æœå‹™ï¼ˆå¯é¸ï¼‰
    
    Returns:
        è¦†ç›¤å ±å‘Šæ–‡æœ¬
    """
    logger.info("é–‹å§‹åŸ·è¡Œå¤§ç›¤è¦†ç›¤åˆ†æ...")
    
    try:
        market_analyzer = MarketAnalyzer(
            search_service=search_service,
            analyzer=analyzer
        )
        
        # åŸ·è¡Œå¾©ç›¤
        review_report = market_analyzer.run_daily_review()
        
        if review_report:
            # ä¿å­˜å ±å‘Šåˆ°æ–‡ä»¶
            date_str = datetime.now().strftime('%Y%m%d')
            report_filename = f"market_review_{date_str}.md"
            filepath = notifier.save_report_to_file(
                f"# ğŸ¯ å¤§ç›¤è¦†ç›¤\n\n{review_report}", 
                report_filename
            )
            logger.info(f"å¤§ç›¤è¦†ç›¤å ±å‘Šå·²ä¿å­˜: {filepath}")
            
            # æ¨é€é€šçŸ¥
            if notifier.is_available():
                # æ·»åŠ æ¨™é¡Œ
                report_content = f"ğŸ¯ å¤§ç›¤è¦†ç›¤\n\n{review_report}"
                
                success = notifier.send(report_content)
                if success:
                    logger.info("å¤§ç›¤è¦†ç›¤æ¨é€æˆåŠŸ")
                else:
                    logger.warning("å¤§ç›¤è¦†ç›¤æ¨é€å¤±æ•—")
            
            return review_report
        
    except Exception as e:
        logger.error(f"å¤§ç›¤è¦†ç›¤åˆ†æå¤±æ•—: {e}")
    
    return None


def run_full_analysis(
    config: Config,
    args: argparse.Namespace,
    stock_codes: Optional[List[str]] = None
):
    """
    åŸ·è¡Œå®Œæ•´çš„åˆ†ææµç¨‹ï¼ˆå€‹è‚¡ + å¤§ç›¤è¦†ç›¤ï¼‰
    
    é€™æ˜¯å®šæ™‚ä»»å‹™èª¿ç”¨çš„ä¸»å‡½æ•¸
    """
    try:
        # å‘½ä»¤è¡Œåƒæ•¸ --single-notify è¦†è“‹é…ç½®ï¼ˆ#55ï¼‰
        if getattr(args, 'single_notify', False):
            config.single_stock_notify = True
        
        # å‰µå»ºèª¿åº¦å™¨
        pipeline = StockAnalysisPipeline(
            config=config,
            max_workers=args.workers
        )
        
        # 1. é‹è¡Œå€‹è‚¡åˆ†æ
        results = pipeline.run(
            stock_codes=stock_codes,
            dry_run=args.dry_run,
            send_notification=not args.no_notify
        )
        
        # 2. é‹è¡Œå¤§ç›¤è¦†ç›¤ï¼ˆå¦‚æœå•Ÿç”¨ä¸”ä¸æ˜¯åƒ…å€‹è‚¡æ¨¡å¼ï¼‰
        market_report = ""
        if config.market_review_enabled and not args.no_market_review:
            # åªèª¿ç”¨ä¸€æ¬¡ï¼Œä¸¦ç²å–çµæœ
            review_result = run_market_review(
                notifier=pipeline.notifier,
                analyzer=pipeline.analyzer,
                search_service=pipeline.search_service
            )
            # å¦‚æœæœ‰çµæœï¼Œè³¦å€¼çµ¦ market_report ç”¨æ–¼å¾ŒçºŒé£›æ›¸æ–‡æª”ç”Ÿæˆ
            if review_result:
                market_report = review_result
        
        # è¼¸å‡ºæ‘˜è¦
        if results:
            logger.info("\n===== åˆ†æçµæœæ‘˜è¦ =====")
            for r in sorted(results, key=lambda x: x.sentiment_score, reverse=True):
                emoji = r.get_emoji()
                logger.info(
                    f"{emoji} {r.name}({r.code}): {r.operation_advice} | "
                    f"è©•åˆ† {r.sentiment_score} | {r.trend_prediction}"
                )
        
        logger.info("\nä»»å‹™åŸ·è¡Œå®Œæˆ")

        # === æ–°å¢ï¼šç”Ÿæˆé£›æ›¸é›²æ–‡æª” ===
        try:
            feishu_doc = FeishuDocManager()
            if feishu_doc.is_configured() and (results or market_report):
                logger.info("æ­£åœ¨å‰µå»ºé£›æ›¸é›²æ–‡æª”...")

                # 1. æº–å‚™æ¨™é¡Œ "01-01 13:01å¤§ç›¤è¦†ç›¤"
                tz_cn = timezone(timedelta(hours=8))
                now = datetime.now(tz_cn)
                doc_title = f"{now.strftime('%Y-%m-%d %H:%M')} å¤§ç›¤è¦†ç›¤"

                # 2. æº–å‚™å…§å®¹ (æ‹¼æ¥å€‹è‚¡åˆ†æå’Œå¤§ç›¤è¦†ç›¤)
                full_content = ""

                # æ·»åŠ å¤§ç›¤è¦†ç›¤å…§å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
                if market_report:
                    full_content += f"# ğŸ“ˆ å¤§ç›¤è¦†ç›¤\n\n{market_report}\n\n---\n\n"

                # æ·»åŠ å€‹è‚¡æ±ºç­–å„€è¡¨ç›¤ï¼ˆä½¿ç”¨ NotificationService ç”Ÿæˆï¼‰
                if results:
                    dashboard_content = pipeline.notifier.generate_dashboard_report(results)
                    full_content += f"# ğŸš€ å€‹è‚¡æ±ºç­–å„€è¡¨ç›¤\n\n{dashboard_content}"

                # 3. å‰µå»ºæ–‡æª”
                doc_url = feishu_doc.create_daily_doc(doc_title, full_content)
                if doc_url:
                    logger.info(f"é£›æ›¸é›²æ–‡æª”å‰µå»ºæˆåŠŸ: {doc_url}")
                    # å¯é¸ï¼šå°‡æ–‡æª”éˆæ¥ä¹Ÿæ¨é€åˆ°ç¾¤è£¡
                    pipeline.notifier.send(f"[{now.strftime('%Y-%m-%d %H:%M')}] è¦†ç›¤æ–‡æª”å‰µå»ºæˆåŠŸ: {doc_url}")

        except Exception as e:
            logger.error(f"é£›æ›¸æ–‡æª”ç”Ÿæˆå¤±æ•—: {e}")
        
    except Exception as e:
        logger.exception(f"åˆ†ææµç¨‹åŸ·è¡Œå¤±æ•—: {e}")


def start_bot_stream_clients(config: Config) -> None:
    """Start bot stream clients when enabled in config."""
    # å•Ÿå‹•é‡˜é‡˜ Stream å®¢æˆ¶ç«¯
    if config.dingtalk_stream_enabled:
        try:
            from bot.platforms import start_dingtalk_stream_background, DINGTALK_STREAM_AVAILABLE
            if DINGTALK_STREAM_AVAILABLE:
                if start_dingtalk_stream_background():
                    logger.info("[Main] Dingtalk Stream client started in background.")
                else:
                    logger.warning("[Main] Dingtalk Stream client failed to start.")
            else:
                logger.warning("[Main] Dingtalk Stream enabled but SDK is missing.")
                logger.warning("[Main] Run: pip install dingtalk-stream")
        except Exception as exc:
            logger.error(f"[Main] Failed to start Dingtalk Stream client: {exc}")

    # å•Ÿå‹•é£›æ›¸ Stream å®¢æˆ¶ç«¯
    if getattr(config, 'feishu_stream_enabled', False):
        try:
            from bot.platforms import start_feishu_stream_background, FEISHU_SDK_AVAILABLE
            if FEISHU_SDK_AVAILABLE:
                if start_feishu_stream_background():
                    logger.info("[Main] Feishu Stream client started in background.")
                else:
                    logger.warning("[Main] Feishu Stream client failed to start.")
            else:
                logger.warning("[Main] Feishu Stream enabled but SDK is missing.")
                logger.warning("[Main] Run: pip install lark-oapi")
        except Exception as exc:
            logger.error(f"[Main] Failed to start Feishu Stream client: {exc}")


def main() -> int:
    """
    ä¸»å…¥å£å‡½æ•¸
    
    Returns:
        é€€å‡ºç¢¼ï¼ˆ0 è¡¨ç¤ºæˆåŠŸï¼‰
    """
    # è§£æå‘½ä»¤è¡Œåƒæ•¸
    args = parse_arguments()
    
    # åŠ è¼‰é…ç½®ï¼ˆåœ¨è¨­ç½®æ—¥èªŒå‰åŠ è¼‰ï¼Œä»¥ç²å–æ—¥èªŒç›®éŒ„ï¼‰
    config = get_config()
    
    # é…ç½®æ—¥èªŒï¼ˆè¼¸å‡ºåˆ°æ§åˆ¶æª¯å’Œæ–‡ä»¶ï¼‰
    setup_logging(debug=args.debug, log_dir=config.log_dir)
    
    logger.info("=" * 60)
    logger.info("Aè‚¡è‡ªé¸è‚¡æ™ºèƒ½åˆ†æç³»çµ± å•Ÿå‹•")
    logger.info(f"é‹è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)
    
    # é©—è­‰é…ç½®
    warnings = config.validate()
    for warning in warnings:
        logger.warning(warning)
    
    # è§£æè‚¡ç¥¨åˆ—è¡¨
    stock_codes = None
    if args.stocks:
        stock_codes = [code.strip() for code in args.stocks.split(',') if code.strip()]
        logger.info(f"ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„è‚¡ç¥¨åˆ—è¡¨: {stock_codes}")
    
    # === å•Ÿå‹• WebUI (å¦‚æœå•Ÿç”¨) ===
    # å„ªå…ˆç´š: å‘½ä»¤è¡Œåƒæ•¸ > é…ç½®æ–‡ä»¶
    start_webui = (args.webui or args.webui_only or config.webui_enabled) and os.getenv("GITHUB_ACTIONS") != "true"
    
    if start_webui:
        try:
            from webui import run_server_in_thread
            run_server_in_thread(host=config.webui_host, port=config.webui_port)
            start_bot_stream_clients(config)
        except Exception as e:
            logger.error(f"å•Ÿå‹• WebUI å¤±æ•—: {e}")
    
    # === åƒ… WebUI æ¨¡å¼ï¼šä¸è‡ªå‹•åŸ·è¡Œåˆ†æ ===
    if args.webui_only:
        logger.info("æ¨¡å¼: åƒ… WebUI æœå‹™")
        logger.info(f"WebUI é‹è¡Œä¸­: http://{config.webui_host}:{config.webui_port}")
        logger.info("é€šé /analysis?code=xxx æ¥å£æ‰‹å‹•è§¸ç™¼åˆ†æ")
        logger.info("æŒ‰ Ctrl+C é€€å‡º...")
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            logger.info("\nç”¨æˆ¶ä¸­æ–·ï¼Œç¨‹åºé€€å‡º")
        return 0

    try:
        # æ¨¡å¼1: åƒ…å¤§ç›¤è¦†ç›¤
        if args.market_review:
            logger.info("æ¨¡å¼: åƒ…å¤§ç›¤è¦†ç›¤")
            notifier = NotificationService()
            
            # åˆå§‹åŒ–æœç´¢æœå‹™å’Œåˆ†æå™¨ï¼ˆå¦‚æœæœ‰é…ç½®ï¼‰
            search_service = None
            analyzer = None
            
            if config.bocha_api_keys or config.tavily_api_keys or config.serpapi_keys:
                search_service = SearchService(
                    bocha_keys=config.bocha_api_keys,
                    tavily_keys=config.tavily_api_keys,
                    serpapi_keys=config.serpapi_keys
                )
            
            if config.gemini_api_key:
                analyzer = GeminiAnalyzer(api_key=config.gemini_api_key)
            
            run_market_review(notifier, analyzer, search_service)
            return 0
        
        # æ¨¡å¼2: å®šæ™‚ä»»å‹™æ¨¡å¼
        if args.schedule or config.schedule_enabled:
            logger.info("æ¨¡å¼: å®šæ™‚ä»»å‹™")
            logger.info(f"æ¯æ—¥åŸ·è¡Œæ™‚é–“: {config.schedule_time}")
            
            from scheduler import run_with_schedule
            
            def scheduled_task():
                run_full_analysis(config, args, stock_codes)
            
            run_with_schedule(
                task=scheduled_task,
                schedule_time=config.schedule_time,
                run_immediately=True  # å•Ÿå‹•æ™‚å…ˆåŸ·è¡Œä¸€æ¬¡
            )
            return 0
        
        # æ¨¡å¼3: æ­£å¸¸å–®æ¬¡é‹è¡Œ
        run_full_analysis(config, args, stock_codes)
        
        logger.info("\nç¨‹åºåŸ·è¡Œå®Œæˆ")
        
        # å¦‚æœå•Ÿç”¨äº† WebUI ä¸”æ˜¯éå®šæ™‚ä»»å‹™æ¨¡å¼ï¼Œä¿æŒç¨‹åºé‹è¡Œä»¥ä¾¿è¨ªå• WebUI
        if start_webui and not (args.schedule or config.schedule_enabled):
            logger.info("WebUI é‹è¡Œä¸­ (æŒ‰ Ctrl+C é€€å‡º)...")
            try:
                # ç°¡å–®çš„ä¿æŒæ´»èºå¾ªç’°
                while True:
                    time.sleep(1)
            except KeyboardInterrupt:
                pass
        
        return 0
        
    except KeyboardInterrupt:
        logger.info("\nç”¨æˆ¶ä¸­æ–·ï¼Œç¨‹åºé€€å‡º")
        return 130
        
    except Exception as e:
        logger.exception(f"ç¨‹åºåŸ·è¡Œå¤±æ•—: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
